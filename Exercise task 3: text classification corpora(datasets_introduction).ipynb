{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Introduction-to-Human-Language-Technology/blob/main/Exercise%20task%203%3A%20text%20classification%20corpora(datasets_introduction).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to the `datasets` library\n",
        "\n",
        "This notebook serves as an introduction to the `datasets` Python library and in part as an introduction to the associated dataset repository of the same name. The datasets repository is located at <https://huggingface.co/datasets> and the library documentation is found at <https://huggingface.co/docs/datasets>."
      ],
      "metadata": {
        "id": "siPHL0GJVxbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Setup\n",
        "\n",
        "Install the `datasets` Python package on the system."
      ],
      "metadata": {
        "id": "14gW_lRIWw60"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cOd1KAqMVkzN"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the `datasets` library."
      ],
      "metadata": {
        "id": "WKetL9ZfkSeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets"
      ],
      "metadata": {
        "id": "ErJfLLrJkRF0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disable the progress bar to make output from dataset loading a bit less verbose. (This only affects what shows on screen.)"
      ],
      "metadata": {
        "id": "V1NnpHDAW4lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#datasets.disable_progress_bar()"
      ],
      "metadata": {
        "id": "fqsLt5dbVulR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Loading a dataset\n",
        "\n",
        "We can load a dataset from the repository simply by invoking the `load_dataset` function with the name of the dataset. We can also similarly use the function `load_dataset_builder` to get some general information about the dataset.\n",
        "\n",
        "* [Documentation for `load_dataset`](https://huggingface.co/docs/datasets/package_reference/loading_methods#datasets.load_dataset)\n",
        "* [Documentation for `load_dataset_builder`](https://huggingface.co/docs/datasets/package_reference/loading_methods#datasets.load_dataset_builder)\n",
        "\n",
        "It's worth exploring the search and filtering functions of the repository (<https://huggingface.co/datasets>) to get an idea of what datasets are available. For example, how many datasets are there in your native language?"
      ],
      "metadata": {
        "id": "UvofKwEOiC1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_emotion = 'emotion'\n",
        "DATASET_rotten_tomatoes = 'rotten_tomatoes'\n",
        "DATASET_snli = 'snli'\n",
        "DATASET_sst2 = 'sst2'\n",
        "DATASET_emo = 'emo'"
      ],
      "metadata": {
        "id": "a0GiCraxAPwh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_emotion = datasets.load_dataset(DATASET_emotion)\n",
        "dataset_rotten_tomatoes = datasets.load_dataset(DATASET_rotten_tomatoes)\n",
        "dataset_snli = datasets.load_dataset(DATASET_snli)\n",
        "dataset_sst2 = datasets.load_dataset(DATASET_sst2)\n",
        "dataset_emo = datasets.load_dataset(DATASET_emo)"
      ],
      "metadata": {
        "id": "D1gbDiAeW0-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed637b6-d93e-442b-8133-37d03852e3f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "builder_emotion = datasets.load_dataset_builder(DATASET_emotion)\n",
        "builder_rotten_tomatoes = datasets.load_dataset_builder(DATASET_rotten_tomatoes)\n",
        "builder_snli = datasets.load_dataset_builder(DATASET_snli)\n",
        "builder_sst2 = datasets.load_dataset_builder(DATASET_sst2)\n",
        "builder_emo = datasets.load_dataset_builder(DATASET_emo)"
      ],
      "metadata": {
        "id": "7VDfmhyn-bt3",
        "outputId": "9f12b10a-51e4-4bf8-8e88-4fa9b29cbd4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## General dataset information\n",
        "\n",
        "We can find various pieces of information about the corpus in the `info` field of the object returned by `load_dataset_builder`. (Note that not all datasets in the repositiry will have useful information here.)"
      ],
      "metadata": {
        "id": "jTm5sek-zx_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', builder_emotion.info.description)\n",
        "print('\\nrotten_tomatoes:\\n', builder_rotten_tomatoes.info.description)\n",
        "print('\\nsnli:\\n', builder_snli.info.description)\n",
        "print('\\nsst2:\\n', builder_sst2.info.description)\n",
        "print('\\nemo:\\n', builder_emo.info.description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF-uWK89zacP",
        "outputId": "73721d65-8d7b-4a93-c558-0d2bab2eb953"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.\n",
            "\n",
            "\n",
            "rotten_tomatoes:\n",
            " \n",
            "\n",
            "snli:\n",
            " \n",
            "\n",
            "sst2:\n",
            " \n",
            "\n",
            "emo:\n",
            " In this dataset, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', builder_emotion.info.citation)\n",
        "print('\\nrotten_tomatoes:\\n', builder_rotten_tomatoes.info.citation)\n",
        "print('\\nsnli:\\n', builder_snli.info.citation)\n",
        "print('\\nsst2:\\n', builder_sst2.info.citation)\n",
        "print('\\nemo:\\n', builder_emo.info.citation)"
      ],
      "metadata": {
        "id": "nyOqQ6rJ_Dqm",
        "outputId": "a0dcbe8d-caa9-4dde-8b3f-d21e61e729d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " @inproceedings{saravia-etal-2018-carer,\n",
            "    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
            "    author = \"Saravia, Elvis  and\n",
            "      Liu, Hsien-Chi Toby  and\n",
            "      Huang, Yen-Hao  and\n",
            "      Wu, Junlin  and\n",
            "      Chen, Yi-Shin\",\n",
            "    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
            "    month = oct # \"-\" # nov,\n",
            "    year = \"2018\",\n",
            "    address = \"Brussels, Belgium\",\n",
            "    publisher = \"Association for Computational Linguistics\",\n",
            "    url = \"https://www.aclweb.org/anthology/D18-1404\",\n",
            "    doi = \"10.18653/v1/D18-1404\",\n",
            "    pages = \"3687--3697\",\n",
            "    abstract = \"Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.\",\n",
            "}\n",
            "\n",
            "\n",
            "rotten_tomatoes:\n",
            " \n",
            "\n",
            "snli:\n",
            " \n",
            "\n",
            "sst2:\n",
            " \n",
            "\n",
            "emo:\n",
            " @inproceedings{chatterjee-etal-2019-semeval,\n",
            "    title={SemEval-2019 Task 3: EmoContext Contextual Emotion Detection in Text},\n",
            "    author={Ankush Chatterjee and Kedhar Nath Narahari and Meghana Joshi and Puneet Agrawal},\n",
            "    booktitle={Proceedings of the 13th International Workshop on Semantic Evaluation},\n",
            "    year={2019},\n",
            "    address={Minneapolis, Minnesota, USA},\n",
            "    publisher={Association for Computational Linguistics},\n",
            "    url={https://www.aclweb.org/anthology/S19-2005},\n",
            "    doi={10.18653/v1/S19-2005},\n",
            "    pages={39--48},\n",
            "    abstract={In this paper, we present the SemEval-2019 Task 3 - EmoContext: Contextual Emotion Detection in Text. Lack of facial expressions and voice modulations make detecting emotions in text a challenging problem. For instance, as humans, on reading ''Why don't you ever text me!'' we can either interpret it as a sad or angry emotion and the same ambiguity exists for machines. However, the context of dialogue can prove helpful in detection of the emotion. In this task, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others. To facilitate the participation in this task, textual dialogues from user interaction with a conversational agent were taken and annotated for emotion classes after several data processing steps. A training data set of 30160 dialogues, and two evaluation data sets, Test1 and Test2, containing 2755 and 5509 dialogues respectively were released to the participants. A total of 311 teams made submissions to this task. The final leader-board was evaluated on Test2 data set, and the highest ranked submission achieved 79.59 micro-averaged F1 score. Our analysis of systems submitted to the task indicate that Bi-directional LSTM was the most common choice of neural architecture used, and most of the systems had the best performance for the Sad emotion class, and the worst for the Happy emotion class}\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the description suggests, you can refer to the paper <https://www.aclweb.org/anthology/D18-1404> for more information about the dataset."
      ],
      "metadata": {
        "id": "42Esvbvktljj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## `Dataset` and `DatasetDict`\n",
        "\n",
        "Let's have a look at the dataset itself next. This is the most important object for using datasets -- the builder is mostly useful for general information about a dataset."
      ],
      "metadata": {
        "id": "UG5dHEfa1V8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', dataset_emotion)\n",
        "print('\\nrotten_tomatoes:\\n', dataset_rotten_tomatoes)\n",
        "print('\\nsnli:\\n', dataset_snli)\n",
        "print('\\nsst2:\\n', dataset_sst2)\n",
        "print('\\nemo:\\n', dataset_emo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q_pUV1YXBoa",
        "outputId": "cb499023-de26-41a4-d484-e3b7db73ec1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 16000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n",
            "\n",
            "rotten_tomatoes:\n",
            " DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 8530\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1066\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1066\n",
            "    })\n",
            "})\n",
            "\n",
            "snli:\n",
            " DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label'],\n",
            "        num_rows: 550152\n",
            "    })\n",
            "})\n",
            "\n",
            "sst2:\n",
            " DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['idx', 'sentence', 'label'],\n",
            "        num_rows: 67349\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['idx', 'sentence', 'label'],\n",
            "        num_rows: 872\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['idx', 'sentence', 'label'],\n",
            "        num_rows: 1821\n",
            "    })\n",
            "})\n",
            "\n",
            "emo:\n",
            " DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 30160\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 5509\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see here `Dataset` objects keyed with `train`, `validation` and `test`. `Dataset` is the central class of the `datasets` library, representing a structured collection of data (e.g. a text corpus, or a part of a text corpus). Each of the three datasets has features `text` and `label`, as we would expect for a text classification dataset. We can also see `num_rows` for each of the three datasets; this is the number of examples in each of the train, development and test subsets of the data.\n",
        "\n",
        "Note that the top-level object here isn't a `Dataset` but rather a `DatasetDict`. This object is analogous to a Python dictionary: you can access the `Dataset` objects that it holds by the dictionary keys (here `train`, `validation` and `test`). For convenience, the `DatasetDict` object also implements `Dataset` functions (e.g. `map`) which, when called, invoke the same function on the `Dataset` objects.\n",
        "\n",
        "* [Documentation for `Dataset`](https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.Dataset)\n",
        "* [Documentation for `DatasetDict`](https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.DatasetDict)\n",
        "\n",
        "We can get any of the `Dataset` objects by indexing the `DatasetDict` with one of its keys:"
      ],
      "metadata": {
        "id": "hSDUQbtRYDcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', dataset_emotion['train'])\n",
        "print('\\nrotten_tomatoes:\\n', dataset_rotten_tomatoes['train'])\n",
        "print('\\nsnli:\\n', dataset_snli['train'])\n",
        "print('\\nsst2:\\n', dataset_sst2['train'])\n",
        "print('\\nemo:\\n', dataset_emo['train'])"
      ],
      "metadata": {
        "id": "hyrNGZ3RXkgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d199742-1ba8-4273-c63f-e8211e8fc326"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 16000\n",
            "})\n",
            "\n",
            "rotten_tomatoes:\n",
            " Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 8530\n",
            "})\n",
            "\n",
            "snli:\n",
            " Dataset({\n",
            "    features: ['premise', 'hypothesis', 'label'],\n",
            "    num_rows: 550152\n",
            "})\n",
            "\n",
            "sst2:\n",
            " Dataset({\n",
            "    features: ['idx', 'sentence', 'label'],\n",
            "    num_rows: 67349\n",
            "})\n",
            "\n",
            "emo:\n",
            " Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 30160\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## `Dataset` contents\n",
        "\n",
        "Let's work on the train `Dataset` for now."
      ],
      "metadata": {
        "id": "NRoFqWKmuc_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_emotion = dataset_emotion['train']\n",
        "train_dataset_rotten_tomatoes = dataset_rotten_tomatoes['train']\n",
        "train_dataset_snli = dataset_snli['train']\n",
        "train_dataset_sst2 = dataset_sst2['train']\n",
        "train_dataset_emo = dataset_emo['train']"
      ],
      "metadata": {
        "id": "m2OhGe86u021"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw above, this `Dataset` has the features `text` and `label`, and there are 16,000 examples in the dataset, i.e. 16,000 (`text`, `label`) pairs."
      ],
      "metadata": {
        "id": "ndjbpeAnu7VC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', train_dataset_emotion)\n",
        "print('\\nrotten_tomatoes:\\n', train_dataset_rotten_tomatoes)\n",
        "print('\\nsnli:\\n', train_dataset_snli)\n",
        "print('\\nsst2:\\n', train_dataset_sst2)\n",
        "print('\\nemo:\\n', train_dataset_emo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JkkBiBgvMvQ",
        "outputId": "5966fcb5-2e94-4782-9b28-9b0d05056d06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 16000\n",
            "})\n",
            "\n",
            "rotten_tomatoes:\n",
            " Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 8530\n",
            "})\n",
            "\n",
            "snli:\n",
            " Dataset({\n",
            "    features: ['premise', 'hypothesis', 'label'],\n",
            "    num_rows: 550152\n",
            "})\n",
            "\n",
            "sst2:\n",
            " Dataset({\n",
            "    features: ['idx', 'sentence', 'label'],\n",
            "    num_rows: 67349\n",
            "})\n",
            "\n",
            "emo:\n",
            " Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 30160\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data contained in the `Dataset` object can be accessed by indexing the object in one of two basic ways:\n",
        "\n",
        "* by row (integer), giving the values of the features for a particular example\n",
        "* by feature name (string), giving the value of that feature for all rows\n",
        "\n",
        "(Like `list` objects, we can also slice the `Dataset` object by indexing with  two integers `start:end`.)\n",
        "\n",
        "Let's first look at an individual example (row):"
      ],
      "metadata": {
        "id": "2Im5-tFtvPHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', train_dataset_emotion[0])\n",
        "print('\\nrotten_tomatoes:\\n', train_dataset_rotten_tomatoes[0])\n",
        "print('\\nsnli:\\n', train_dataset_snli[0])\n",
        "print('\\nsst2:\\n', train_dataset_sst2[0])\n",
        "print('\\nemo:\\n', train_dataset_emo[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDJjbLCBvdpc",
        "outputId": "c3958e73-62bf-47c4-d9dd-f4a8ea60a60f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " {'text': 'i didnt feel humiliated', 'label': 0}\n",
            "\n",
            "rotten_tomatoes:\n",
            " {'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'label': 1}\n",
            "\n",
            "snli:\n",
            " {'premise': 'A person on a horse jumps over a broken down airplane.', 'hypothesis': 'A person is training his horse for a competition.', 'label': 1}\n",
            "\n",
            "sst2:\n",
            " {'idx': 0, 'sentence': 'hide new secretions from the parental units ', 'label': 0}\n",
            "\n",
            "emo:\n",
            " {'text': \"don't worry  i'm girl hmm how do i know if you are what's ur name\", 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first ten rows:"
      ],
      "metadata": {
        "id": "_Ugywht6w5kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', train_dataset_emotion[0:10])\n",
        "print('\\nrotten_tomatoes:\\n', train_dataset_rotten_tomatoes[0:10])\n",
        "print('\\nsnli:\\n', train_dataset_snli[0:10])\n",
        "print('\\nsst2:\\n', train_dataset_sst2[0:10])\n",
        "print('\\nemo:\\n', train_dataset_emo[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJuwJEBew8SH",
        "outputId": "4b00a71a-0832-41c1-cac0-31a8164c92ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " {'text': ['i didnt feel humiliated', 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'im grabbing a minute to post i feel greedy wrong', 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'i am feeling grouchy', 'ive been feeling a little burdened lately wasnt sure why that was', 'ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny', 'i feel as confused about life as a teenager or as jaded as a year old man', 'i have been with petronas for years i feel that petronas has performed well and made a huge profit', 'i feel romantic too'], 'label': [0, 0, 3, 2, 3, 0, 5, 4, 1, 2]}\n",
            "\n",
            "rotten_tomatoes:\n",
            " {'text': ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .', 'effective but too-tepid biopic', 'if you sometimes like to go to the movies to have fun , wasabi is a good place to start .', \"emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\", 'the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .', 'offers that rare combination of entertainment and education .', 'perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .', \"steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\", 'take care of my cat offers a refreshingly different slice of asian cinema .'], 'label': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "snli:\n",
            " {'premise': ['A person on a horse jumps over a broken down airplane.', 'A person on a horse jumps over a broken down airplane.', 'A person on a horse jumps over a broken down airplane.', 'Children smiling and waving at camera', 'Children smiling and waving at camera', 'Children smiling and waving at camera', 'A boy is jumping on skateboard in the middle of a red bridge.', 'A boy is jumping on skateboard in the middle of a red bridge.', 'A boy is jumping on skateboard in the middle of a red bridge.', 'An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.'], 'hypothesis': ['A person is training his horse for a competition.', 'A person is at a diner, ordering an omelette.', 'A person is outdoors, on a horse.', 'They are smiling at their parents', 'There are children present', 'The kids are frowning', 'The boy skates down the sidewalk.', 'The boy does a skateboarding trick.', 'The boy is wearing safety equipment.', 'An older man drinks his juice as he waits for his daughter to get off work.'], 'label': [1, 2, 0, 1, 0, 2, 2, 0, 1, 1]}\n",
            "\n",
            "sst2:\n",
            " {'idx': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'sentence': ['hide new secretions from the parental units ', 'contains no wit , only labored gags ', 'that loves its characters and communicates something rather beautiful about human nature ', 'remains utterly satisfied to remain the same throughout ', 'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up ', \"that 's far too tragic to merit such superficial treatment \", 'demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . ', 'of saucy ', \"a depressed fifteen-year-old 's suicidal poetry \", \"are more deeply thought through than in most ` right-thinking ' films \"], 'label': [0, 0, 1, 0, 0, 0, 1, 1, 0, 1]}\n",
            "\n",
            "emo:\n",
            " {'text': [\"don't worry  i'm girl hmm how do i know if you are what's ur name\", 'when did i saw many times i think  no i never saw you', 'by by google chrome where you live', 'u r ridiculous i might be ridiculous but i am telling the truth u little disgusting whore', 'just for time pass wt do u do 4 a living then maybe', \"i'm a dog person youre so rude whaaaat why\", 'so whatsup nothing much sitting sipping and watching tv how abt u what are you watching on tv', 'ok ok im back so how are u', 'really really really really really really y saying so many timesi can hear you', 'bay in the bay faceblowingakiss love you'], 'label': [0, 3, 0, 3, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Note above that slicing doesn't give a list of dictionaries, but rather a single dictionary where the values are lists.)\n",
        "\n",
        "First ten texts:"
      ],
      "metadata": {
        "id": "XC1_cvFnxFxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', train_dataset_emotion['text'][0:10])\n",
        "print('\\nrotten_tomatoes:\\n', train_dataset_rotten_tomatoes['text'][0:10])\n",
        "print('\\nsnli:\\n', train_dataset_snli['premise'][0:10])\n",
        "print('\\nsst2:\\n', train_dataset_sst2['sentence'][0:10])\n",
        "print('\\nemo:\\n', train_dataset_emo['text'][0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuBfKEJ-w-UA",
        "outputId": "c11f4a30-dace-4b97-f827-3039889bd186"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " ['i didnt feel humiliated', 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'im grabbing a minute to post i feel greedy wrong', 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'i am feeling grouchy', 'ive been feeling a little burdened lately wasnt sure why that was', 'ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny', 'i feel as confused about life as a teenager or as jaded as a year old man', 'i have been with petronas for years i feel that petronas has performed well and made a huge profit', 'i feel romantic too']\n",
            "\n",
            "rotten_tomatoes:\n",
            " ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .', 'effective but too-tepid biopic', 'if you sometimes like to go to the movies to have fun , wasabi is a good place to start .', \"emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\", 'the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .', 'offers that rare combination of entertainment and education .', 'perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .', \"steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\", 'take care of my cat offers a refreshingly different slice of asian cinema .']\n",
            "\n",
            "snli:\n",
            " ['A person on a horse jumps over a broken down airplane.', 'A person on a horse jumps over a broken down airplane.', 'A person on a horse jumps over a broken down airplane.', 'Children smiling and waving at camera', 'Children smiling and waving at camera', 'Children smiling and waving at camera', 'A boy is jumping on skateboard in the middle of a red bridge.', 'A boy is jumping on skateboard in the middle of a red bridge.', 'A boy is jumping on skateboard in the middle of a red bridge.', 'An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.']\n",
            "\n",
            "sst2:\n",
            " ['hide new secretions from the parental units ', 'contains no wit , only labored gags ', 'that loves its characters and communicates something rather beautiful about human nature ', 'remains utterly satisfied to remain the same throughout ', 'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up ', \"that 's far too tragic to merit such superficial treatment \", 'demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . ', 'of saucy ', \"a depressed fifteen-year-old 's suicidal poetry \", \"are more deeply thought through than in most ` right-thinking ' films \"]\n",
            "\n",
            "emo:\n",
            " [\"don't worry  i'm girl hmm how do i know if you are what's ur name\", 'when did i saw many times i think  no i never saw you', 'by by google chrome where you live', 'u r ridiculous i might be ridiculous but i am telling the truth u little disgusting whore', 'just for time pass wt do u do 4 a living then maybe', \"i'm a dog person youre so rude whaaaat why\", 'so whatsup nothing much sitting sipping and watching tv how abt u what are you watching on tv', 'ok ok im back so how are u', 'really really really really really really y saying so many timesi can hear you', 'bay in the bay faceblowingakiss love you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First ten labels:"
      ],
      "metadata": {
        "id": "r_FUPNq4xLm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', train_dataset_emotion['label'][0:10])\n",
        "print('\\nrotten_tomatoes:\\n', train_dataset_rotten_tomatoes['label'][0:10])\n",
        "print('\\nsnli:\\n', train_dataset_snli['label'][0:10])\n",
        "print('\\nsst2:\\n', train_dataset_sst2['label'][0:10])\n",
        "print('\\nemo:\\n', train_dataset_emo['label'][0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TYnDVxJxI-f",
        "outputId": "fbbd28ca-6805-47ee-c100-668ab17fc5bb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " [0, 0, 3, 2, 3, 0, 5, 4, 1, 2]\n",
            "\n",
            "rotten_tomatoes:\n",
            " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n",
            "snli:\n",
            " [1, 2, 0, 1, 0, 2, 2, 0, 1, 1]\n",
            "\n",
            "sst2:\n",
            " [0, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
            "\n",
            "emo:\n",
            " [0, 3, 0, 3, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Feature names\n",
        "\n",
        "Note above that the labels are integers. This is convenient for machine learning, but makes the data difficult to interpret. To make sense of the integer labels, we can look at the `features` for the dataset\n",
        "\n",
        "* [Documentation for dataset features](https://huggingface.co/docs/datasets/about_dataset_features)"
      ],
      "metadata": {
        "id": "gfXAUIKuxSBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', train_dataset_emotion.features)\n",
        "print('\\nrotten_tomatoes:\\n', train_dataset_rotten_tomatoes.features)\n",
        "print('\\nsnli:\\n', train_dataset_snli.features)\n",
        "print('\\nsst2:\\n', train_dataset_sst2.features)\n",
        "print('\\nemo:\\n', train_dataset_emo.features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54ckZ-MExOzR",
        "outputId": "ae74b4bd-3b20-4240-c87f-7477d0052436"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}\n",
            "\n",
            "rotten_tomatoes:\n",
            " {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}\n",
            "\n",
            "snli:\n",
            " {'premise': Value(dtype='string', id=None), 'hypothesis': Value(dtype='string', id=None), 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)}\n",
            "\n",
            "sst2:\n",
            " {'idx': Value(dtype='int32', id=None), 'sentence': Value(dtype='string', id=None), 'label': ClassLabel(names=['negative', 'positive'], id=None)}\n",
            "\n",
            "emo:\n",
            " {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['others', 'happy', 'sad', 'angry'], id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a `ClassLabel` object keyed by `'label'` that has a `names` attribute. Let's pick that out into a `label_names` attribute for convenience:"
      ],
      "metadata": {
        "id": "BUNJifwzyxlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_emotion = train_dataset_emotion.features['label'].names\n",
        "\n",
        "print('emotion:\\n', label_emotion)\n",
        "\n",
        "label_rotten_tomatoes = train_dataset_rotten_tomatoes.features['label'].names\n",
        "\n",
        "print('\\nrotten_tomatoes:\\n', label_rotten_tomatoes)\n",
        "\n",
        "label_snli = train_dataset_snli.features['label'].names\n",
        "\n",
        "print('\\nsnli:\\n', label_snli)\n",
        "\n",
        "label_sst2 = train_dataset_sst2.features['label'].names\n",
        "\n",
        "print('\\nsst2:\\n', label_sst2)\n",
        "\n",
        "label_emo = train_dataset_emo.features['label'].names\n",
        "\n",
        "print('\\nemo:\\n', label_emo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTD25_yFyc7w",
        "outputId": "34ec0e6d-634b-4306-fbab-8d283455999b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
            "\n",
            "rotten_tomatoes:\n",
            " ['neg', 'pos']\n",
            "\n",
            "snli:\n",
            " ['entailment', 'neutral', 'contradiction']\n",
            "\n",
            "sst2:\n",
            " ['negative', 'positive']\n",
            "\n",
            "emo:\n",
            " ['others', 'happy', 'sad', 'angry']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now use this list to convert the integer labels into human-readable strings to interpret them."
      ],
      "metadata": {
        "id": "7YcE3qM2zfCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('emotion:\\n', 'text :', train_dataset_emotion[3]['text'])\n",
        "print('emotion:\\n', 'label:', train_dataset_emotion[3]['label'])\n",
        "print('---')\n",
        "print('emotion:\\n', 'text :', train_dataset_emotion[3]['text'])\n",
        "print('emotion:\\n', 'label:', label_emotion[train_dataset_emotion[3]['label']])\n",
        "\n",
        "print('\\nrotten_tomatoes:\\n', 'text :', train_dataset_rotten_tomatoes[3]['text'])\n",
        "print('\\nrotten_tomatoes:\\n', 'label:', train_dataset_rotten_tomatoes[3]['label'])\n",
        "print('---')\n",
        "print('\\nrotten_tomatoes:\\n', 'text :', train_dataset_rotten_tomatoes[3]['text'])\n",
        "print('\\nrotten_tomatoes:\\n', 'label:', label_rotten_tomatoes[train_dataset_rotten_tomatoes[3]['label']])\n",
        "\n",
        "print('\\nsnli:\\n', 'premise :', train_dataset_snli[3]['premise'])\n",
        "print('\\nsnli:\\n', 'label:', train_dataset_snli[3]['label'])\n",
        "print('---')\n",
        "print('\\nsnli:\\n', 'premise :', train_dataset_snli[3]['premise'])\n",
        "print('\\nsnli:\\n', 'label:', label_snli[train_dataset_snli[3]['label']])\n",
        "\n",
        "print('\\nsst2:\\n', 'sentence :', train_dataset_sst2[3]['sentence'])\n",
        "print('\\nsst2:\\n', 'label:', train_dataset_sst2[3]['label'])\n",
        "print('---')\n",
        "print('\\nsst2:\\n', 'sentence :', train_dataset_sst2[3]['sentence'])\n",
        "print('\\nsst2:\\n', 'label:', label_sst2[train_dataset_sst2[3]['label']])\n",
        "\n",
        "print('\\nemo:\\n', 'text :', train_dataset_emo[3]['text'])\n",
        "print('\\nemo:\\n', 'label:', train_dataset_emo[3]['label'])\n",
        "print('---')\n",
        "print('\\nemo:\\n', 'text :', train_dataset_emo[3]['text'])\n",
        "print('\\nemo:\\n', 'label:', label_emo[train_dataset_emo[3]['label']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoCWtL2HzCVr",
        "outputId": "3a7d942d-8f38-4148-da07-4be056aef865"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion:\n",
            " text : i am ever feeling nostalgic about the fireplace i will know that it is still on the property\n",
            "emotion:\n",
            " label: 2\n",
            "---\n",
            "emotion:\n",
            " text : i am ever feeling nostalgic about the fireplace i will know that it is still on the property\n",
            "emotion:\n",
            " label: love\n",
            "\n",
            "rotten_tomatoes:\n",
            " text : if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
            "\n",
            "rotten_tomatoes:\n",
            " label: 1\n",
            "---\n",
            "\n",
            "rotten_tomatoes:\n",
            " text : if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
            "\n",
            "rotten_tomatoes:\n",
            " label: pos\n",
            "\n",
            "snli:\n",
            " premise : Children smiling and waving at camera\n",
            "\n",
            "snli:\n",
            " label: 1\n",
            "---\n",
            "\n",
            "snli:\n",
            " premise : Children smiling and waving at camera\n",
            "\n",
            "snli:\n",
            " label: neutral\n",
            "\n",
            "sst2:\n",
            " sentence : remains utterly satisfied to remain the same throughout \n",
            "\n",
            "sst2:\n",
            " label: 0\n",
            "---\n",
            "\n",
            "sst2:\n",
            " sentence : remains utterly satisfied to remain the same throughout \n",
            "\n",
            "sst2:\n",
            " label: negative\n",
            "\n",
            "emo:\n",
            " text : u r ridiculous i might be ridiculous but i am telling the truth u little disgusting whore\n",
            "\n",
            "emo:\n",
            " label: 3\n",
            "---\n",
            "\n",
            "emo:\n",
            " text : u r ridiculous i might be ridiculous but i am telling the truth u little disgusting whore\n",
            "\n",
            "emo:\n",
            " label: angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset_snli[3].keys())\n"
      ],
      "metadata": {
        "id": "uA47XMfQHoKM",
        "outputId": "582c503d-02b4-4e04-c31a-5b6549a2b5c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['premise', 'hypothesis', 'label'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "That concludes our introductory look into datasets. For more information on the library and the repository, please see [the `datasets` documentation](https://huggingface.co/docs/datasets)."
      ],
      "metadata": {
        "id": "hxXHV67j1OBg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xui79sUVblDw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "def distribution(dataset_name):\n",
        "    dataset = load_dataset(dataset_name)\n",
        "    labels = dataset['train']['label']\n",
        "    label_counts = Counter(labels)\n",
        "    label_names = dataset['train'].features['label'].names\n",
        "    total_samples = len(dataset['train']) + len(dataset.get('validation', [])) + len(dataset['test'])\n",
        "    train_size = (len(dataset['train']) / total_samples) * 100\n",
        "    validation_size = (len(dataset.get('validation', [])) / total_samples) * 100\n",
        "    test_size = (len(dataset['test']) / total_samples) * 100\n",
        "    label_percentages = ((label_names[label], (count / len(labels)) * 100) for label, count in label_counts.items())\n",
        "    print(f\"Distributions in \\\"{dataset_name}\\\":\")\n",
        "    print(f\"Train: {train_size:.2f}%, Validation: {validation_size:.2f}%, Test: {test_size:.2f}%\")\n",
        "    print('\\n'.join([f\"{label_name}: {percentage:.2f}%\" for label_name, percentage in label_percentages]))"
      ],
      "metadata": {
        "id": "pf06vMDPOIfn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset_name in ['emotion', 'rotten_tomatoes', 'snli', 'sst2', 'emo']:\n",
        "    print()\n",
        "    distribution(dataset_name)"
      ],
      "metadata": {
        "id": "OPG4iojUOw80",
        "outputId": "15ef5ed9-d91f-48ef-9689-8a07403fac29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distributions in \"emotion\":\n",
            "Train: 80.00%, Validation: 10.00%, Test: 10.00%\n",
            "sadness: 29.16%\n",
            "anger: 13.49%\n",
            "love: 8.15%\n",
            "surprise: 3.57%\n",
            "fear: 12.11%\n",
            "joy: 33.51%\n",
            "\n",
            "Distributions in \"rotten_tomatoes\":\n",
            "Train: 80.00%, Validation: 10.00%, Test: 10.00%\n",
            "pos: 50.00%\n",
            "neg: 50.00%\n",
            "\n",
            "Distributions in \"snli\":\n",
            "Train: 96.49%, Validation: 1.75%, Test: 1.75%\n",
            "neutral: 33.22%\n",
            "contradiction: 33.30%\n",
            "entailment: 33.34%\n",
            "contradiction: 0.14%\n",
            "\n",
            "Distributions in \"sst2\":\n",
            "Train: 96.16%, Validation: 1.24%, Test: 2.60%\n",
            "negative: 44.22%\n",
            "positive: 55.78%\n",
            "\n",
            "Distributions in \"emo\":\n",
            "Train: 84.56%, Validation: 0.00%, Test: 15.44%\n",
            "others: 49.56%\n",
            "angry: 18.26%\n",
            "sad: 18.11%\n",
            "happy: 14.07%\n"
          ]
        }
      ]
    }
  ]
}