{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Introduction-to-Human-Language-Technology/blob/main/Exercise%20task%203%3A%20text%20classification%20corpora(datasets_introduction).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to the `datasets` library\n",
        "\n",
        "This notebook serves as an introduction to the `datasets` Python library and in part as an introduction to the associated dataset repository of the same name. The datasets repository is located at <https://huggingface.co/datasets> and the library documentation is found at <https://huggingface.co/docs/datasets>."
      ],
      "metadata": {
        "id": "siPHL0GJVxbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Setup\n",
        "\n",
        "Install the `datasets` Python package on the system."
      ],
      "metadata": {
        "id": "14gW_lRIWw60"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cOd1KAqMVkzN",
        "outputId": "658372e0-64df-49a0-f4a6-983a7169e41e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the `datasets` library."
      ],
      "metadata": {
        "id": "WKetL9ZfkSeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets"
      ],
      "metadata": {
        "id": "ErJfLLrJkRF0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disable the progress bar to make output from dataset loading a bit less verbose. (This only affects what shows on screen.)"
      ],
      "metadata": {
        "id": "V1NnpHDAW4lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets.disable_progress_bar()"
      ],
      "metadata": {
        "id": "fqsLt5dbVulR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Loading a dataset\n",
        "\n",
        "We can load a dataset from the repository simply by invoking the `load_dataset` function with the name of the dataset. We can also similarly use the function `load_dataset_builder` to get some general information about the dataset.\n",
        "\n",
        "* [Documentation for `load_dataset`](https://huggingface.co/docs/datasets/package_reference/loading_methods#datasets.load_dataset)\n",
        "* [Documentation for `load_dataset_builder`](https://huggingface.co/docs/datasets/package_reference/loading_methods#datasets.load_dataset_builder)\n",
        "\n",
        "It's worth exploring the search and filtering functions of the repository (<https://huggingface.co/datasets>) to get an idea of what datasets are available. For example, how many datasets are there in your native language?"
      ],
      "metadata": {
        "id": "UvofKwEOiC1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_NAME = 'emotion'\n",
        "\n",
        "dataset = datasets.load_dataset(DATASET_NAME)\n",
        "builder = datasets.load_dataset_builder(DATASET_NAME)"
      ],
      "metadata": {
        "id": "D1gbDiAeW0-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e35ee8-24ea-47d0-bf10-6fc02d32f153"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## General dataset information\n",
        "\n",
        "We can find various pieces of information about the corpus in the `info` field of the object returned by `load_dataset_builder`. (Note that not all datasets in the repositiry will have useful information here.)"
      ],
      "metadata": {
        "id": "jTm5sek-zx_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(builder.info.description)\n",
        "print(builder.info.citation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF-uWK89zacP",
        "outputId": "85db9648-3efc-460f-f979-ff59f88c39d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.\n",
            "\n",
            "@inproceedings{saravia-etal-2018-carer,\n",
            "    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
            "    author = \"Saravia, Elvis  and\n",
            "      Liu, Hsien-Chi Toby  and\n",
            "      Huang, Yen-Hao  and\n",
            "      Wu, Junlin  and\n",
            "      Chen, Yi-Shin\",\n",
            "    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
            "    month = oct # \"-\" # nov,\n",
            "    year = \"2018\",\n",
            "    address = \"Brussels, Belgium\",\n",
            "    publisher = \"Association for Computational Linguistics\",\n",
            "    url = \"https://www.aclweb.org/anthology/D18-1404\",\n",
            "    doi = \"10.18653/v1/D18-1404\",\n",
            "    pages = \"3687--3697\",\n",
            "    abstract = \"Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.\",\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the description suggests, you can refer to the paper <https://www.aclweb.org/anthology/D18-1404> for more information about the dataset."
      ],
      "metadata": {
        "id": "42Esvbvktljj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## `Dataset` and `DatasetDict`\n",
        "\n",
        "Let's have a look at the dataset itself next. This is the most important object for using datasets -- the builder is mostly useful for general information about a dataset."
      ],
      "metadata": {
        "id": "UG5dHEfa1V8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q_pUV1YXBoa",
        "outputId": "40758d34-2e9b-4fe2-dcf8-f4cdc737ec20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 16000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see here `Dataset` objects keyed with `train`, `validation` and `test`. `Dataset` is the central class of the `datasets` library, representing a structured collection of data (e.g. a text corpus, or a part of a text corpus). Each of the three datasets has features `text` and `label`, as we would expect for a text classification dataset. We can also see `num_rows` for each of the three datasets; this is the number of examples in each of the train, development and test subsets of the data.\n",
        "\n",
        "Note that the top-level object here isn't a `Dataset` but rather a `DatasetDict`. This object is analogous to a Python dictionary: you can access the `Dataset` objects that it holds by the dictionary keys (here `train`, `validation` and `test`). For convenience, the `DatasetDict` object also implements `Dataset` functions (e.g. `map`) which, when called, invoke the same function on the `Dataset` objects.\n",
        "\n",
        "* [Documentation for `Dataset`](https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.Dataset)\n",
        "* [Documentation for `DatasetDict`](https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.DatasetDict)\n",
        "\n",
        "We can get any of the `Dataset` objects by indexing the `DatasetDict` with one of its keys:"
      ],
      "metadata": {
        "id": "hSDUQbtRYDcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train']"
      ],
      "metadata": {
        "id": "hyrNGZ3RXkgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf2fa31-46a4-4316-b585-4e42e77c4423"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 16000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## `Dataset` contents\n",
        "\n",
        "Let's work on the train `Dataset` for now."
      ],
      "metadata": {
        "id": "NRoFqWKmuc_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset['train']"
      ],
      "metadata": {
        "id": "m2OhGe86u021"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw above, this `Dataset` has the features `text` and `label`, and there are 16,000 examples in the dataset, i.e. 16,000 (`text`, `label`) pairs."
      ],
      "metadata": {
        "id": "ndjbpeAnu7VC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JkkBiBgvMvQ",
        "outputId": "337ef81b-6486-4c2d-bbe6-76c3992a521a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 16000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data contained in the `Dataset` object can be accessed by indexing the object in one of two basic ways:\n",
        "\n",
        "* by row (integer), giving the values of the features for a particular example\n",
        "* by feature name (string), giving the value of that feature for all rows\n",
        "\n",
        "(Like `list` objects, we can also slice the `Dataset` object by indexing with  two integers `start:end`.)\n",
        "\n",
        "Let's first look at an individual example (row):"
      ],
      "metadata": {
        "id": "2Im5-tFtvPHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDJjbLCBvdpc",
        "outputId": "e4ed26ec-a300-4dea-a808-063d76cbcced"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'i didnt feel humiliated', 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first ten rows:"
      ],
      "metadata": {
        "id": "_Ugywht6w5kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJuwJEBew8SH",
        "outputId": "18e0b0f2-6035-4551-9211-d6e8ae384122"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['i didnt feel humiliated',\n",
              "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              "  'im grabbing a minute to post i feel greedy wrong',\n",
              "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              "  'i am feeling grouchy',\n",
              "  'ive been feeling a little burdened lately wasnt sure why that was',\n",
              "  'ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny',\n",
              "  'i feel as confused about life as a teenager or as jaded as a year old man',\n",
              "  'i have been with petronas for years i feel that petronas has performed well and made a huge profit',\n",
              "  'i feel romantic too'],\n",
              " 'label': [0, 0, 3, 2, 3, 0, 5, 4, 1, 2]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Note above that slicing doesn't give a list of dictionaries, but rather a single dictionary where the values are lists.)\n",
        "\n",
        "First ten texts:"
      ],
      "metadata": {
        "id": "XC1_cvFnxFxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset['text'][0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuBfKEJ-w-UA",
        "outputId": "515a6b34-8c32-4d86-b8d2-4c046e99655e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i didnt feel humiliated',\n",
              " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              " 'im grabbing a minute to post i feel greedy wrong',\n",
              " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              " 'i am feeling grouchy',\n",
              " 'ive been feeling a little burdened lately wasnt sure why that was',\n",
              " 'ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny',\n",
              " 'i feel as confused about life as a teenager or as jaded as a year old man',\n",
              " 'i have been with petronas for years i feel that petronas has performed well and made a huge profit',\n",
              " 'i feel romantic too']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First ten labels:"
      ],
      "metadata": {
        "id": "r_FUPNq4xLm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset['label'][0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TYnDVxJxI-f",
        "outputId": "cb8a81bf-85b1-41d8-f431-107eb6c9282a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 3, 2, 3, 0, 5, 4, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Feature names\n",
        "\n",
        "Note above that the labels are integers. This is convenient for machine learning, but makes the data difficult to interpret. To make sense of the integer labels, we can look at the `features` for the dataset\n",
        "\n",
        "* [Documentation for dataset features](https://huggingface.co/docs/datasets/about_dataset_features)"
      ],
      "metadata": {
        "id": "gfXAUIKuxSBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54ckZ-MExOzR",
        "outputId": "211314a6-720f-47e2-829c-380cd39a7314"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a `ClassLabel` object keyed by `'label'` that has a `names` attribute. Let's pick that out into a `label_names` attribute for convenience:"
      ],
      "metadata": {
        "id": "BUNJifwzyxlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = train_dataset.features['label'].names\n",
        "\n",
        "label_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTD25_yFyc7w",
        "outputId": "680dcbb8-c8fb-4dec-bc02-bffb6e9af918"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now use this list to convert the integer labels into human-readable strings to interpret them."
      ],
      "metadata": {
        "id": "7YcE3qM2zfCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('text :', train_dataset[3]['text'])\n",
        "print('label:', train_dataset[3]['label'])\n",
        "print('---')\n",
        "print('text :', train_dataset[3]['text'])\n",
        "print('label:', label_names[train_dataset[3]['label']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoCWtL2HzCVr",
        "outputId": "acecec61-6f24-4800-d23d-aee04f29a2be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text : i am ever feeling nostalgic about the fireplace i will know that it is still on the property\n",
            "label: 2\n",
            "---\n",
            "text : i am ever feeling nostalgic about the fireplace i will know that it is still on the property\n",
            "label: love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "That concludes our introductory look into datasets. For more information on the library and the repository, please see [the `datasets` documentation](https://huggingface.co/docs/datasets)."
      ],
      "metadata": {
        "id": "hxXHV67j1OBg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkZRs_RK5ZiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from collections import Counter\n",
        "\n",
        "def analyze_dataset(dataset_name):\n",
        "    # Load dataset and builder\n",
        "    builder = datasets.load_dataset_builder(dataset_name)\n",
        "\n",
        "    # Print description\n",
        "    print(\"Description of the dataset:\")\n",
        "    print(builder.info.description)\n",
        "\n",
        "    # Calculate relative sizes of subsets\n",
        "    splits = builder.info.splits\n",
        "    total_size = sum(split.num_examples for split in splits.values())\n",
        "\n",
        "    relative_sizes = {split_name: (split.num_examples / total_size) * 100 for split_name, split in splits.items()}\n",
        "\n",
        "    print(\"\\nRelative sizes of subsets:\")\n",
        "    for split_name, percentage in relative_sizes.items():\n",
        "        print(f\"{split_name}: {percentage:.2f}%\")\n",
        "\n",
        "    # Calculate label distribution in 'train' subset\n",
        "    train_dataset = datasets.load_dataset(dataset_name, split='train')\n",
        "    train_labels = train_dataset['label']\n",
        "    label_counts = Counter(train_labels)\n",
        "    train_size = len(train_labels)\n",
        "\n",
        "    label_percentage = {label_name: (count / train_size) * 100 for label_name, count in label_counts.items()}\n",
        "\n",
        "    print(\"\\nDistribution of labels in the 'train' subset:\")\n",
        "    for label_name, percentage in label_percentage.items():\n",
        "        print(f\"{label_name}: {percentage:.2f}%\")\n",
        "\n",
        "# Apply function to the specified datasets\n",
        "datasets_to_analyze = ['emotion', 'rotten_tomatoes', 'snli', 'sst2', 'emo']\n",
        "for dataset_name in datasets_to_analyze:\n",
        "    print(f\"\\nAnalyzing dataset: {dataset_name}\\n\")\n",
        "    analyze_dataset(dataset_name)\n"
      ],
      "metadata": {
        "id": "bVW0Y4TV5Zna",
        "outputId": "ad9a8a3a-7789-4d7d-95a7-9e0bf3ff4cd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing dataset: emotion\n",
            "\n",
            "Description of the dataset:\n",
            "Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.\n",
            "\n",
            "\n",
            "Relative sizes of subsets:\n",
            "train: 80.00%\n",
            "validation: 10.00%\n",
            "test: 10.00%\n",
            "\n",
            "Distribution of labels in the 'train' subset:\n",
            "0: 29.16%\n",
            "3: 13.49%\n",
            "2: 8.15%\n",
            "5: 3.57%\n",
            "4: 12.11%\n",
            "1: 33.51%\n",
            "\n",
            "Analyzing dataset: rotten_tomatoes\n",
            "\n",
            "Description of the dataset:\n",
            "\n",
            "\n",
            "Relative sizes of subsets:\n",
            "train: 80.00%\n",
            "validation: 10.00%\n",
            "test: 10.00%\n",
            "\n",
            "Distribution of labels in the 'train' subset:\n",
            "1: 50.00%\n",
            "0: 50.00%\n",
            "\n",
            "Analyzing dataset: snli\n",
            "\n",
            "Description of the dataset:\n",
            "\n",
            "\n",
            "Relative sizes of subsets:\n",
            "test: 1.75%\n",
            "validation: 1.75%\n",
            "train: 96.49%\n",
            "\n",
            "Distribution of labels in the 'train' subset:\n",
            "1: 33.22%\n",
            "2: 33.30%\n",
            "0: 33.34%\n",
            "-1: 0.14%\n",
            "\n",
            "Analyzing dataset: sst2\n",
            "\n",
            "Description of the dataset:\n",
            "\n",
            "\n",
            "Relative sizes of subsets:\n",
            "train: 96.16%\n",
            "validation: 1.24%\n",
            "test: 2.60%\n",
            "\n",
            "Distribution of labels in the 'train' subset:\n",
            "0: 44.22%\n",
            "1: 55.78%\n",
            "\n",
            "Analyzing dataset: emo\n",
            "\n",
            "Description of the dataset:\n",
            "In this dataset, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others.\n",
            "\n",
            "\n",
            "Relative sizes of subsets:\n",
            "train: 84.56%\n",
            "test: 15.44%\n",
            "\n",
            "Distribution of labels in the 'train' subset:\n",
            "0: 49.56%\n",
            "3: 18.26%\n",
            "2: 18.11%\n",
            "1: 14.07%\n"
          ]
        }
      ]
    }
  ]
}