{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Introduction-to-Human-Language-Technology/blob/main/Exercise%20task%2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text generation example\n",
        "\n",
        "This is a brief example of how to run text generation with a causal language model and `pipeline`.\n",
        "\n",
        "Install [transformers](https://huggingface.co/docs/transformers/index) python package. This will be used to load the model and tokenizer and to run generation."
      ],
      "metadata": {
        "id": "tIQ1s96UCcJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers"
      ],
      "metadata": {
        "id": "4fUBJmXHCHw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the `AutoTokenizer`, `AutoModelForCausalLM`, and `pipeline` classes. The first two support loading tokenizers and generative models from the [Hugging Face repository](https://huggingface.co/models), and the last wraps a tokenizer and a model for convenience."
      ],
      "metadata": {
        "id": "5ZRNZgRJCt6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwyK005xCFSF"
      },
      "outputs": [],
      "source": [
        "#from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load a generative model and its tokenizer. You can substitute any other generative model name here (e.g. [other TurkuNLP GPT-3 models](https://huggingface.co/models?sort=downloads&search=turkunlp%2Fgpt3)), but note that Colab may have issues running larger models."
      ],
      "metadata": {
        "id": "6QJPDe3ZC_sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL_NAME = 'TurkuNLP/gpt3-finnish-large'\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "#model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "wqTxn_QaCNjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate a text generation pipeline using the tokenizer and model."
      ],
      "metadata": {
        "id": "9ADWWb77e1sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "pipe = pipeline(\n",
        "    'text-generation',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=model.device\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "id": "0IIJzNrEe5qx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5c7d8388-9aae-4af9-9d19-4126989f8a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\npipe = pipeline(\\n    'text-generation',\\n    model=model,\\n    tokenizer=tokenizer,\\n    device=model.device\\n)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now call the pipeline with a text prompt; it will take care of tokenizing, encoding, generation, and decoding:"
      ],
      "metadata": {
        "id": "eAohNr1ciwaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "output = pipe('Terve, miten menee?', max_new_tokens=25)\n",
        "\n",
        "print(output)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jWcOJkiKi5vr",
        "outputId": "e6fdaa79-00bf-4dd3-bd2b-88619c138874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\noutput = pipe('Terve, miten menee?', max_new_tokens=25)\\n\\nprint(output)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just print the text"
      ],
      "metadata": {
        "id": "SNRMsxXOjSo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "9Op7MJ6XjahG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also call the pipeline with any arguments that the model `generate` function supports. For details on text generation using `transformers`, see e.g. [this tutorial](https://huggingface.co/blog/how-to-generate).\n",
        "\n",
        "Example with sampling and a high `temperature` parameter to generate more chaotic output:"
      ],
      "metadata": {
        "id": "YROp3hyikXPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "output = pipe(\n",
        "    'Terve, miten menee?',\n",
        "    do_sample=True,\n",
        "    temperature=10.0,\n",
        "    max_new_tokens=25\n",
        ")\n",
        "\n",
        "print(output[0]['generated_text'])\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "22QjXE88jkim",
        "outputId": "e705a544-5a70-41c6-c42a-94ba94e195c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\noutput = pipe(\\n    'Terve, miten menee?',\\n    do_sample=True,\\n    temperature=10.0,\\n    max_new_tokens=25\\n)\\n\\nprint(output[0]['generated_text'])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model='gpt2-large')\n",
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT5rcoWfgfJp",
        "outputId": "fcf3673e-2d75-4b1c-9dd4-3962f932060f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "person name recognition"
      ],
      "metadata": {
        "id": "D2vd8lF4sX4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBdERwBMhB9u",
        "outputId": "690da546-19a4-4fd7-c21e-9dd3e99a1493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Hello, I'm a language model, but what I'm really doing is making a human-readable version of something with a deep, powerful and expressive\"},\n",
              " {'generated_text': \"Hello, I'm a language model, this is my first commit and I'm going to put it on github. I've also put my code in\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and you'll hear me in this chapter!\\n\\nOne of the features we love is the ability to have\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a developer. If you don't know my code, please don't comment anything on the repo, because\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I'm not a language designer. That should probably be a rule not a rule. I am speaking as a\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#zero_shot\n",
        "generator(\"List the person names occurring in the following texts., John and Mary went to the market.\", max_length=30, num_return_sequences=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ybr3TT7rOYM",
        "outputId": "7fe5cbb3-6617-416f-ffde-80f93b2ca97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'List the person names occurring in the following texts., John and Mary went to the market. \"Then came to him Mary his wife [who was with'},\n",
              " {'generated_text': 'List the person names occurring in the following texts., John and Mary went to the market. Joseph and Hyrum went out to play,Joseph brought'},\n",
              " {'generated_text': 'List the person names occurring in the following texts., John and Mary went to the market. John went a bit earlier., John and Mary went to the'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one_shot\n",
        "generator(['John and Mary went to the market.', \"Sophia and Ethan are siblings.\"], max_length=30, num_return_sequences=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKidQVnMpVGj",
        "outputId": "246b8d23-fd53-4723-f526-a5031351d3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'generated_text': 'John and Mary went to the market. The market was large, full of goods, but there was one thing that seemed unusually common. The people of'},\n",
              "  {'generated_text': 'John and Mary went to the market.\\n\\n3 And it came to pass that on the morrow, while their father was abroad in the city'},\n",
              "  {'generated_text': 'John and Mary went to the market. This was the day before their wedding date. John and Mary were both dressed in plain white gowns, which'}],\n",
              " [{'generated_text': 'Sophia and Ethan are siblings. Despite only having lived together four years, they look older together: Mia has grown a small beard and Elliot has'},\n",
              "  {'generated_text': \"Sophia and Ethan are siblings. Sophia's parents, Mr. and Mrs. Cote, are well-known in their home town of Salem\"},\n",
              "  {'generated_text': 'Sophia and Ethan are siblings. They were living in a small house on a small island off the coast of the Netherlands. Sophia (born January'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#two_shot\n",
        "generator(['John and Mary went to the market.', \"Sophia and Ethan are siblings.\", \"Tom and Sarah are best friends.\"], max_length=30, num_return_sequences=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvzhdfR1pXA8",
        "outputId": "735f8c63-8808-45b5-bd01-c0cd434319f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'generated_text': 'John and Mary went to the market. They bought a loaf of bread; and, as the Lord had commanded Peter and John, they took the loaf'},\n",
              "  {'generated_text': 'John and Mary went to the market. I was waiting for Mary when she told me that her father had gone with the boys to the market with her'},\n",
              "  {'generated_text': 'John and Mary went to the market. She had one of her friends go with her.\"\\n\\nPavrinovich says: \"Pavrin'}],\n",
              " [{'generated_text': 'Sophia and Ethan are siblings. Sophia is a computer science student, and Ethan is a former football player with a serious heart condition that requires 24'},\n",
              "  {'generated_text': 'Sophia and Ethan are siblings. Sophia is a student at Ephraim High School. She is obsessed with the fact that her real parents'},\n",
              "  {'generated_text': \"Sophia and Ethan are siblings. Sophia is Ethan's wife, a well-mannered woman in her late 30s who is not the brightest\"}],\n",
              " [{'generated_text': 'Tom and Sarah are best friends. One day Sarah gets a hold of a picture she took of one of Bob and Sam\\'s kids with a \"H'},\n",
              "  {'generated_text': 'Tom and Sarah are best friends. They are both very young, both from families with a successful history before they came to the world, both are very'},\n",
              "  {'generated_text': 'Tom and Sarah are best friends. After a traumatic car accident when she was two, Sarah spent three years recovering in the hospital. After that, she'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#zero_shot\n",
        "generator(\"This is a first grade math exam. calculate this addition: 1 '+' 2 =\", max_length=20, num_return_sequences=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baDE0-sXvq2G",
        "outputId": "afc795fc-69c8-46c4-d0f6-7cdbde924204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 =' 3\"},\n",
              " {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = 3 or\"},\n",
              " {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = 1 +\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "two-digit addition (e.g. 11 + 22 = 33)"
      ],
      "metadata": {
        "id": "WSiw3h0Usaob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#one_shot\n",
        "generator([\"This is a first grade math exam. calculate this addition: 1 '+' 2 =\", \"This is a first grade math exam. calculate this addition: 11 '+' 22 =\"], max_length=20, num_return_sequences=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8fuSolnsa_e",
        "outputId": "4d4bb6cd-4c25-4a25-ba48-c556c25e4cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 =3 Add\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = 3 '\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = '1\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = ','\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 =' 3\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = '1\"}],\n",
              " [{'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 54.\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = '9\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 ='+\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 21 '\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 3 +\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 100.\"}]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#two_shot\n",
        "generator([\"This is a first grade math exam. calculate this addition: 1 '+' 2 =\", \"This is a first grade math exam. calculate this addition: 11 '+' 22 =\", \"This is a first grade math exam. calculate this addition: 7 '+' 8 =\"], max_length=30, num_return_sequences=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2XY9OlCtcXt",
        "outputId": "a20d6e42-4f21-43ed-9468-831c885fb46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = 3 and it should actually be subtract 5 and multiply 5.\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 =? 3 4 This is my first-grade reading comprehension test\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 =' 4.\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 ='3 '+'(2+3)*6\\n\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = 3 and a sum. The first grade math can never be\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = 3 '-' 3 * 4 = 5 (see how\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = 3\\n\\nFor an example of how to do this,\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = 3 '= 4\\n\\nThe math problem: Add:\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 1 '+' 2 = 5 add 2 = 9 this adds 5 = 9 and 9\"}],\n",
              " [{'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 21\\n\\nIn algebraic notation: 11 '+ '\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 5. add up 5 and divide by 11. that's\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 ='\\n\\n9 '+' 22 ='\\n\\n\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 23 This is a second grade math exam. calculate this subt\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 23 + 24 + 25 = 27 + 28 + 29 +\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 31. divide by this value: 21 '+' 21\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = 5.3.\\n\\nSo you see, all the\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 11 '+' 22 = '+' + 52 = 73. There are four possible\"},\n",
              "  {'generated_text': 'This is a first grade math exam. calculate this addition: 11 \\'+\\' 22 = \\'27.\\n\\n\"If you really want to learn'}],\n",
              " [{'generated_text': \"This is a first grade math exam. calculate this addition: 7 '+' 8 = 7 '+' 9 = 7 '+' 10 =\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 7 '+' 8 = '9' + '/' 9+0 = 10'\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 7 '+' 8 = 0 You must keep your eyes on the board and answer every\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 7 '+' 8 = 9 To get 9, just add the '+' and\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 7 '+' 8 ='9 10 ='/11 add: 7 '+'\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 7 '+' 8 = 4\\n\\nHow many times should a player have to score\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 7 '+' 8 =10 (plus or minus) 13 =16 (plus or\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 7 '+' 8 = 2, therefore 11 plus 2 is 2.\\n\\nNote\"},\n",
              "  {'generated_text': \"This is a first grade math exam. calculate this addition: 7 '+' 8 = 8, which means add 2 and 7 together.\\n\\n\"}]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "binary sentiment classification (positive / negative)"
      ],
      "metadata": {
        "id": "F8Y53zzzylSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#zero_shot\n",
        "generator(\"Do the following texts express a positive or negative sentiment? Sarah is happy these days.\", max_length=20, num_return_sequences=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJu5RzOgwqEx",
        "outputId": "fcca6d93-5f29-426d-cf26-6de6236522ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days.\\n\\n\"'},\n",
              " {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days.\\n\\nMy'},\n",
              " {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days. What he says'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one_shot\n",
        "generator([\"Do the following texts express a positive or negative sentiment? Sarah is happy these days.\", \"Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days.\"], max_length=30, num_return_sequences=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUjEtVlCyoON",
        "outputId": "d793b8db-aa79-4e87-9033-b0573dd94514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'generated_text': \"Do the following texts express a positive or negative sentiment? Sarah is happy these days.\\n\\nCindy is sad about how they've treated their\"},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days. Sarah wants to be happy. (Incorrect) [inform'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days. She sees people come into her clinic everyday to talk about their children'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days. Sarah is very happy.\\n\\nThe following texts express a positive'},\n",
              "  {'generated_text': \"Do the following texts express a positive or negative sentiment? Sarah is happy these days. I'm glad that Sarah is healthy, happy and happy.\\n\"},\n",
              "  {'generated_text': \"Do the following texts express a positive or negative sentiment? Sarah is happy these days. What would it mean if Sarah started working at her friend's pub\"}],\n",
              " [{'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days.\\n\\nSarah: We made'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. They will enjoy their life and'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days.'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. John: You can say this'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. They are both over fifty with'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days.\\n\\nTom: We are'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#two_shot\n",
        "generator([\"Do the following texts express a positive or negative sentiment? Sarah is happy these days.\", \"Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days.\", \"Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people.\"], max_length=40, num_return_sequences=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aldHZTPypVK",
        "outputId": "3e8bd346-b9c0-46e1-9ea1-b4616f9fd99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days.\\n\\nSarah will be the first of the people who died in the storm\\n\\nSarah is not a girl in'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days. The whole family is now in the hospital. The doctors want Sarah to get back in school. The hospital will pay'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days. Will they? Is life any better?\\n\\nCathy is happy these days. Will they? Is life any'},\n",
              "  {'generated_text': \"Do the following texts express a positive or negative sentiment? Sarah is happy these days. Sarah hates them and hopes they don't come back. Sarah wants to send them away. Sarah hates them and wants\"},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days. Sarah is proud of their family. Sarah is sad that they have lost a parent. Will they get to visit with'},\n",
              "  {'generated_text': \"Do the following texts express a positive or negative sentiment? Sarah is happy these days. The way I feel is very good. I'm not very hopeful. I have a friend who wants a baby but\"},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days. You feel happy. Where can you get more happiness? How can you get more than a few minutes together? Is'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah is happy these days. No. This is a negative sentiment, you know? Is there a positive sentiment? No. Is there a negative'},\n",
              "  {'generated_text': \"Do the following texts express a positive or negative sentiment? Sarah is happy these days. I don't know if I can believe that a boy like her has reached this stage. What a wonder. I\"}],\n",
              " [{'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. I love them so much. Their love for each other is so strong. I'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days.'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. Tom as always was a kind soul who could cheer up anyone. Sarah is happy'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. The last two times Tom and Sarah came to Paris for the Eurovision Song Contest'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. Sarah and Tom are working together to make the things they love happen, to keep'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. Sarah in fact, is married and has 3 young children. Sarah loves the company'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. The text, \"Happiness is here.\" is positive and pleasant.\\n\\n\\n'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. Tom, now that he works as an engineer, loves his job and the work'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? Sarah and Tom aer enjoying the life and are happy these days. Tom and Sarah are looking forward into the future. Thomas, Sarah and Tom are'}],\n",
              " [{'generated_text': 'Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people.\\n\\nAll the sentences express the sentiments: The audience'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people. The audience is interested. They enjoy the drama and are'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people.\\n\\nPlease note: All text are based on the'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people. The audience wanted to help the poor by providing blankets,'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people. Do anyone want to help from this point on or do'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people. Their hope is that our countries in the world will be'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people. What do you think? They are saying that these acts'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people. I think the problem is that some people cannot relate with'},\n",
              "  {'generated_text': 'Do the following texts express a positive or negative sentiment? The audiences were very sad to see such disasters around the world and want to help people.\\n\\n\"Sail\" by Hana Handa'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}