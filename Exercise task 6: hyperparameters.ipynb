{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15d9db420191465985b177b7212d560a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5bffce858c646ee8adecfbe31782ce0",
              "IPY_MODEL_1025877dcec54f219bc44e9ac5d423f0",
              "IPY_MODEL_56d12030eb7f49268ffa1c16a09b217f"
            ],
            "layout": "IPY_MODEL_004894cad8b14f23b927bca98d83032b"
          }
        },
        "a5bffce858c646ee8adecfbe31782ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5efdfdae562c47d3aceec7ee67fcaa10",
            "placeholder": "​",
            "style": "IPY_MODEL_52869f7423c749e9a3c9988ce7860e0a",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "1025877dcec54f219bc44e9ac5d423f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab974f96a05a471192fe0d20fdabfe8e",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99ba051c1a9340668dfe0be8b562775f",
            "value": 25000
          }
        },
        "56d12030eb7f49268ffa1c16a09b217f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_802285c028e24fefb9134cf3ec919686",
            "placeholder": "​",
            "style": "IPY_MODEL_bdc7a24273a149749a0d141882fefb49",
            "value": " 25000/25000 [00:21&lt;00:00, 1307.85 examples/s]"
          }
        },
        "004894cad8b14f23b927bca98d83032b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5efdfdae562c47d3aceec7ee67fcaa10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52869f7423c749e9a3c9988ce7860e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab974f96a05a471192fe0d20fdabfe8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99ba051c1a9340668dfe0be8b562775f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "802285c028e24fefb9134cf3ec919686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc7a24273a149749a0d141882fefb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7601fbd4012f4b15b450ef238fdfd002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eecfe0c75c3482e9041794fd9967585",
              "IPY_MODEL_5a1d3d2ab7d8488f93948eeabd3c270c",
              "IPY_MODEL_ca1e09a695494086824c9949adca4dea"
            ],
            "layout": "IPY_MODEL_5e149e742d38405f90e274b94263e3f5"
          }
        },
        "4eecfe0c75c3482e9041794fd9967585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d6b48f39d134dd5909f60d19649dbfb",
            "placeholder": "​",
            "style": "IPY_MODEL_2daa4fcea5b24265b86b830f536b43fb",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "5a1d3d2ab7d8488f93948eeabd3c270c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb5bdcb96ae415eacb5084e0481de78",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6599644eca214fc39b01e35bab32e732",
            "value": 25000
          }
        },
        "ca1e09a695494086824c9949adca4dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecaf841440c34fc0a97d78188190447a",
            "placeholder": "​",
            "style": "IPY_MODEL_4f7081abd57d4ef6af568105340dd49d",
            "value": " 25000/25000 [00:20&lt;00:00, 1197.83 examples/s]"
          }
        },
        "5e149e742d38405f90e274b94263e3f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6b48f39d134dd5909f60d19649dbfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2daa4fcea5b24265b86b830f536b43fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eb5bdcb96ae415eacb5084e0481de78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6599644eca214fc39b01e35bab32e732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecaf841440c34fc0a97d78188190447a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7081abd57d4ef6af568105340dd49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Introduction-to-Human-Language-Technology/blob/main/Exercise%20task%206%3A%20hyperparameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Before we start running our own Python code, install the required Python packages using [pip](https://en.wikipedia.org/wiki/Pip):\n",
        "\n",
        "* [`transformers`](https://huggingface.co/docs/transformers/index) is a popular deep learning package primarily on top of torch, we need to reinstall it with the [torch] configuration (might take a substantial amount of time)\n",
        "* [`datasets`](https://huggingface.co/docs/datasets/) provides support for loading, creating, and manipulating datasets\n",
        "* evaluate is a library of performance metrics (like accuracy etc)\n",
        "\n",
        "**You will likely need to do a Runtime/Restart session for everything to work after the installation.**"
      ],
      "metadata": {
        "id": "LDZZUKzfPRWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q datasets evaluate\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "fKPHBYptQDsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc073f9c-3cbb-4522-8905-097b357cc44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Above, the `!` at the start of the line tells the notebook to run the line as an operating system command rather than Python code, and the `-q` argument to `pip` runs the command in \"quiet\" mode, with less output.)"
      ],
      "metadata": {
        "id": "xOeI-LA9RcYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Get and prepare data\n",
        "\n",
        "*   Let us work with the IMDB dataset of movie review sentiment\n",
        "*   25,000 positive reviews\n",
        "*   25,000 negative reviews\n",
        "*   50,000 unlabeled reviews (which we discard for the time being)\n"
      ],
      "metadata": {
        "id": "_fCdfQfNNzwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint #pprint => pretty-print, I use it occassionally throughout the notebook\n",
        "import datasets\n",
        "import torch\n",
        "dset=datasets.load_dataset(\"imdb\")\n",
        "pprint(dset)"
      ],
      "metadata": {
        "id": "QxmgHoKDTN2_",
        "outputId": "6881cd17-4ca7-4df6-e611-44553826479f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dset=dset.shuffle() #This is never a bad idea, datasets may have ordering to them, which is not what we want\n",
        "del dset[\"unsupervised\"] #Delete the unlabeled part of the dataset, we don't need it for anything"
      ],
      "metadata": {
        "id": "lbmgiOj4pWw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(dset['train'][0]['text'])\n",
        "print(dset['train'][0]['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI3kyD3vry8C",
        "outputId": "3f647bf6-e69e-444f-ba57-5ea74f9ecd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('I would put this at the top of my list of films in the category of '\n",
            " 'unwatchable trash! There are films that are bad, but the worst kind are the '\n",
            " 'ones that are unwatchable but you are suppose to like them because they are '\n",
            " 'supposed to be good for you! The sex sequences, so shocking in its day, '\n",
            " \"couldn't even arouse a rabbit. The so called controversial politics is \"\n",
            " 'strictly high school sophomore amateur night Marxism. The film is '\n",
            " 'self-consciously arty in the worst sense of the term. The photography is in '\n",
            " 'a harsh grainy black and white. Some scenes are out of focus or taken from '\n",
            " 'the wrong angle. Even the sound is bad! And some people call this art?<br '\n",
            " '/><br />')\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize and map vocabulary\n",
        "         \n",
        "*   We need to achieve two complementary tasks\n",
        "*   **Tokenize** split the text into units which can be interpreted as features (words in this case)\n",
        "*   **Map vocabulary** build the feature vector for each example\n",
        "*   Since this is NLP, here it means listing the non-zero elements of the feature vector, or in other words the indices of the vocabulary items\n",
        "* Since we work with the bag of words (BoW) representation, these do not need to be (and are not) in the order in which they appear in the text\n",
        "* These indices then refer to the rows in the embedding matrix\n",
        "*   A traditional and well-tested way it to use sklearn's feature extraction package\n",
        "*   CountVectorizer is most likely what we want in here, because we only want the ids, nothing else\n",
        "* But for other NLP work the TfidfVectorizer is also very handy\n",
        "\n"
      ],
      "metadata": {
        "id": "KMnqQ78cMpk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.feature_extraction\n",
        "\n",
        "# max_features means the size of the vocabulary\n",
        "# which means max_features most-common words\n",
        "vectorizer=sklearn.feature_extraction.text.CountVectorizer(binary=True,max_features=20000)\n",
        "\n",
        "texts=[ex[\"text\"] for ex in dset[\"train\"]] #get a list of all texts from the training data\n",
        "vectorizer.fit(texts) #\"Trains\" the vectorizer, i.e. builds its vocabulary\n"
      ],
      "metadata": {
        "id": "MYOtKJu7Mohd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ff4487a6-da6f-4ced-ee10-b74a6b25baed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(binary=True, max_features=20000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(binary=True, max_features=20000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(binary=True, max_features=20000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the feature vectors\n",
        "\n",
        "* This is super-easy with the vectorizer\n",
        "* It produces a sparse matrix of the non-zero elements"
      ],
      "metadata": {
        "id": "UDNy3w8reO6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_example(ex):\n",
        "    vectorized=vectorizer.transform([ex[\"text\"]]) # [...] because the vectorizer expects a list/iterable over inputs, not one input\n",
        "    non_zero_features=vectorized.nonzero()[1] #.nonzero gives a pair of (rows,columns), we want the columns\n",
        "    non_zero_features+=1 #feature index 0 will have a special meaning\n",
        "                         # so let us not produce it by adding +1 to everything\n",
        "    return {\"input_ids\":non_zero_features}\n",
        "\n",
        "vectorized=vectorize_example(dset[\"train\"][0])"
      ],
      "metadata": {
        "id": "5H9AQOc2rGIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorized)"
      ],
      "metadata": {
        "id": "ECqsgmwTXaOC",
        "outputId": "f4a6d56d-5571-45bc-f4d0-4f5294680375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': array([  797,   891,   918,  1117,  1160,  1184,  1207,  1302,  1516,\n",
            "        1703,  1738,  2006,  2300,  2612,  2679,  2681,  2916,  3889,\n",
            "        4015,  4139,  4627,  6307,  6884,  6894,  7094,  7139,  7344,\n",
            "        7783,  7859,  8268,  8525,  9084,  9595,  9629, 10011, 10453,\n",
            "       10514, 11844, 12086, 12348, 12424, 12492, 12567, 13023, 13175,\n",
            "       13431, 14059, 14137, 15489, 15515, 15713, 15745, 15779, 15838,\n",
            "       15990, 16469, 16533, 16569, 16597, 17138, 17412, 17413, 17621,\n",
            "       17824, 17887, 17891, 17904, 17923, 17938, 17961, 18112, 18172,\n",
            "       18339, 18910, 19588, 19798, 19803, 19848, 19926], dtype=int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can map back to vocabulary and check that everything works\n",
        "# vectorizer.vocabulary_ is a dictionary {key:word, value:idx}\n",
        "\n",
        "idx2word=dict((i,w) for (w,i) in vectorizer.vocabulary_.items()) #inverse the vocab dictionary\n",
        "words=[]\n",
        "for idx in vectorized[\"input_ids\"]:\n",
        "    words.append(idx2word[idx-1]) ## It is easy to forgot we moved all by +1\n",
        "pprint(\", \".join(words)) #This is now the bag of words representation of the document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvgd3IrWfCai",
        "outputId": "76f4f75b-63a1-4370-bea5-4030fcb376f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('amateur, and, angle, are, arouse, art, arty, at, bad, be, because, black, '\n",
            " 'br, but, call, called, category, consciously, controversial, couldn, day, '\n",
            " 'even, film, films, focus, for, from, good, grainy, harsh, high, in, is, its, '\n",
            " 'kind, like, list, my, night, of, ones, or, out, people, photography, '\n",
            " 'politics, put, rabbit, scenes, school, self, sense, sequences, sex, '\n",
            " 'shocking, so, some, sophomore, sound, strictly, suppose, supposed, taken, '\n",
            " 'term, that, the, them, there, they, this, to, top, trash, unwatchable, '\n",
            " 'white, worst, would, wrong, you')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing / vectorizing the whole dataset\n",
        "\n",
        "* The datasets library allows us to efficiently map() a function across the whole dataset\n",
        "* Can run in parallel\n",
        "\n",
        "**Note**: confusingly, and unlike the Python`map` function, [`Dataset.map`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map) function _updates_ its argument dataset, keeping existing values. Here, the call adds the values returned by the function call (here `input_ids`) to each example while also keeping the original `text` and `label` values.\n"
      ],
      "metadata": {
        "id": "i33KIMgkiIn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the tokenizer to the whole dataset using .map()\n",
        "dset_tokenized = dset.map(vectorize_example,num_proc=4)\n",
        "pprint(dset_tokenized[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "15d9db420191465985b177b7212d560a",
            "a5bffce858c646ee8adecfbe31782ce0",
            "1025877dcec54f219bc44e9ac5d423f0",
            "56d12030eb7f49268ffa1c16a09b217f",
            "004894cad8b14f23b927bca98d83032b",
            "5efdfdae562c47d3aceec7ee67fcaa10",
            "52869f7423c749e9a3c9988ce7860e0a",
            "ab974f96a05a471192fe0d20fdabfe8e",
            "99ba051c1a9340668dfe0be8b562775f",
            "802285c028e24fefb9134cf3ec919686",
            "bdc7a24273a149749a0d141882fefb49",
            "7601fbd4012f4b15b450ef238fdfd002",
            "4eecfe0c75c3482e9041794fd9967585",
            "5a1d3d2ab7d8488f93948eeabd3c270c",
            "ca1e09a695494086824c9949adca4dea",
            "5e149e742d38405f90e274b94263e3f5",
            "7d6b48f39d134dd5909f60d19649dbfb",
            "2daa4fcea5b24265b86b830f536b43fb",
            "2eb5bdcb96ae415eacb5084e0481de78",
            "6599644eca214fc39b01e35bab32e732",
            "ecaf841440c34fc0a97d78188190447a",
            "4f7081abd57d4ef6af568105340dd49d"
          ]
        },
        "id": "33xMYRd0q2B9",
        "outputId": "056c5455-49da-4a3b-9a63-62dc270c69ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15d9db420191465985b177b7212d560a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7601fbd4012f4b15b450ef238fdfd002"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [797,\n",
            "               891,\n",
            "               918,\n",
            "               1117,\n",
            "               1160,\n",
            "               1184,\n",
            "               1207,\n",
            "               1302,\n",
            "               1516,\n",
            "               1703,\n",
            "               1738,\n",
            "               2006,\n",
            "               2300,\n",
            "               2612,\n",
            "               2679,\n",
            "               2681,\n",
            "               2916,\n",
            "               3889,\n",
            "               4015,\n",
            "               4139,\n",
            "               4627,\n",
            "               6307,\n",
            "               6884,\n",
            "               6894,\n",
            "               7094,\n",
            "               7139,\n",
            "               7344,\n",
            "               7783,\n",
            "               7859,\n",
            "               8268,\n",
            "               8525,\n",
            "               9084,\n",
            "               9595,\n",
            "               9629,\n",
            "               10011,\n",
            "               10453,\n",
            "               10514,\n",
            "               11844,\n",
            "               12086,\n",
            "               12348,\n",
            "               12424,\n",
            "               12492,\n",
            "               12567,\n",
            "               13023,\n",
            "               13175,\n",
            "               13431,\n",
            "               14059,\n",
            "               14137,\n",
            "               15489,\n",
            "               15515,\n",
            "               15713,\n",
            "               15745,\n",
            "               15779,\n",
            "               15838,\n",
            "               15990,\n",
            "               16469,\n",
            "               16533,\n",
            "               16569,\n",
            "               16597,\n",
            "               17138,\n",
            "               17412,\n",
            "               17413,\n",
            "               17621,\n",
            "               17824,\n",
            "               17887,\n",
            "               17891,\n",
            "               17904,\n",
            "               17923,\n",
            "               17938,\n",
            "               17961,\n",
            "               18112,\n",
            "               18172,\n",
            "               18339,\n",
            "               18910,\n",
            "               19588,\n",
            "               19798,\n",
            "               19803,\n",
            "               19848,\n",
            "               19926],\n",
            " 'label': 0,\n",
            " 'text': 'I would put this at the top of my list of films in the category of '\n",
            "         'unwatchable trash! There are films that are bad, but the worst kind '\n",
            "         'are the ones that are unwatchable but you are suppose to like them '\n",
            "         'because they are supposed to be good for you! The sex sequences, so '\n",
            "         \"shocking in its day, couldn't even arouse a rabbit. The so called \"\n",
            "         'controversial politics is strictly high school sophomore amateur '\n",
            "         'night Marxism. The film is self-consciously arty in the worst sense '\n",
            "         'of the term. The photography is in a harsh grainy black and white. '\n",
            "         'Some scenes are out of focus or taken from the wrong angle. Even the '\n",
            "         'sound is bad! And some people call this art?<br /><br />'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input encoding for MLP\n",
        "\n",
        "* Our `input_ids` are an array containing the indices of the tokens found in the text\n",
        "* This corresponds to the indices into the row of the embedding matrix in the model\n",
        "* That seems to be exactly what we need!\n"
      ],
      "metadata": {
        "id": "XTtyHQpIIJWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batching and padding\n",
        "\n",
        "* When working with neural networks, one rarely trains one example at a time\n",
        "* Instead, processing always happens a batch at a time\n",
        "* This has two important reasons:\n",
        "  1. No batching is too slow (GPU parallelization cannot kick in across examples)\n",
        "  2. The gradients are averaged across the whole batch and applied only once, i.e. batching acts as a regularizer and improves the stability of the training\n"
      ],
      "metadata": {
        "id": "JvaP1DpHjI3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding and Collation (forming a batch)\n",
        "\n",
        "## Padding:\n",
        "\n",
        "* In order to build a batch as a 2D array of (example, seq), we need to fit together examples of different length\n",
        "* Solution: pad the shorter examples with zeroes to the length of the longest example in the batch\n",
        "* Make sure that zero is understood as padding value rather than a (hypothetical) feature with index 0\n",
        "* This is best shown by example, it is in the end easier than it may sound\n",
        "\n",
        "## Collation:\n",
        "\n",
        "* Much like examples are dictionaries with the data, also batches are dictionaries with the data\n",
        "* The only difference is that in a batch, all data tensors have one extra dimension, that's all there is to it\n",
        "\n",
        "## Collator function:\n",
        "\n",
        "* Padding and collation is taken care of by a single function in the HF libraries\n",
        "* It receives a list of examples, and returns a ready batch\n",
        "* The surrounding library code takes care of forming these lists\n",
        "* Let's try to implement one below"
      ],
      "metadata": {
        "id": "hNYxw92nj51B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) I need to define it here, will explain below\n",
        "# 2) I show here a very straightforward implementation of padding and collation\n",
        "# 3) Normally, one would use transformers.DataCollatorWithPadding but that assumes\n",
        "#    a particular tokenizer, to which it outsources much of the work, and we do not\n",
        "#    have it\n",
        "def collator(list_of_examples):\n",
        "    #this is easy, labels are made into a single tensor\n",
        "    batch={\"labels\":torch.tensor(list(ex[\"label\"] for ex in list_of_examples))}\n",
        "    #the worse bit is now to pad the examples, as they are of different length\n",
        "    tensors=[]\n",
        "    max_len=max(len(example[\"input_ids\"]) for example in list_of_examples) #this is the longest example in the batch\n",
        "    #everything needs to be padded to fit in length the longest example\n",
        "    #(so we can build a single tensor out of it)\n",
        "    for example in list_of_examples:\n",
        "        ids=torch.tensor(example[\"input_ids\"]) #pick the input ids\n",
        "        # pad(what,(from_left, from_right)) <- this is how we call the stock pad function\n",
        "        padded=torch.nn.functional.pad(ids,(0,max_len-ids.shape[0])) #pad by max - current length, pads with zero by default\n",
        "        tensors.append(padded) #accumulated the padded ids\n",
        "    batch[\"input_ids\"]=torch.vstack(tensors) #now that we have all of them the same length, a simple vstack() stacks them up\n",
        "    return batch #...and that's all there is to it\n",
        "\n",
        "\n",
        "\n",
        "#Build a batch from 2 examples, with padding\n",
        "batch=collator([dset_tokenized[\"train\"][2],dset_tokenized[\"train\"][7]])\n",
        "print(\"Shape of labels:\",batch[\"labels\"].shape)\n",
        "print(\"Shape of input_ids:\",batch[\"input_ids\"].shape)\n",
        "pprint(batch[\"labels\"])\n",
        "pprint(batch[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXXDxNo6kwfA",
        "outputId": "ce703e40-3390-451e-a5ff-59e9f0019718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of labels: torch.Size([2])\n",
            "Shape of input_ids: torch.Size([2, 314])\n",
            "tensor([1, 1])\n",
            "tensor([[  250,   307,   731,   888,   891,  1117,  1209,  1302,  1815,  3076,\n",
            "          3593,  4637,  4966,  5091,  6105,  6296,  6456,  7139,  7327,  7344,\n",
            "          7403,  7433,  7673,  7719,  7767,  7783,  8092,  8306,  8339,  8767,\n",
            "          8770,  8773,  8921,  9084,  9595,  9621, 10156, 10616, 10620, 10624,\n",
            "         11081, 11443, 11746, 11749, 11844, 11980, 12047, 12146, 12421, 12783,\n",
            "         12936, 13277, 14326, 14337, 14855, 14999, 15230, 15359, 15838, 15922,\n",
            "         16469, 17471, 17891, 17911, 17938, 18066, 18112, 18127, 18919, 19049,\n",
            "         19112, 19352, 19396, 19412, 19507, 19517, 19593, 19625, 19647, 19711,\n",
            "         19771, 19772, 19926,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0],\n",
            "        [  307,   424,   426,   593,   598,   609,   619,   766,   775,   789,\n",
            "           863,   891,   967,  1004,  1037,  1075,  1117,  1159,  1209,  1286,\n",
            "          1302,  1343,  1389,  1652,  1654,  1757,  1780,  1795,  1809,  1883,\n",
            "          1900,  2184,  2188,  2204,  2274,  2285,  2300,  2408,  2579,  2612,\n",
            "          2633,  2676,  2717,  2736,  2791,  2877,  3251,  3278,  3539,  3679,\n",
            "          3682,  4075,  4212,  4238,  4309,  4544,  4618,  4793,  4914,  4967,\n",
            "          4973,  5006,  5095,  5169,  5187,  5257,  5377,  5500,  5503,  5728,\n",
            "          5761,  5827,  5859,  5896,  6021,  6051,  6058,  6120,  6156,  6307,\n",
            "          6320,  6372,  6447,  6479,  6510,  6559,  6649,  6664,  6717,  6745,\n",
            "          6787,  6863,  6880,  6884,  6894,  6901,  6903,  6911,  6927,  7095,\n",
            "          7139,  7145,  7214,  7344,  7380,  7531,  7618,  7682,  7743,  7783,\n",
            "          7969,  8026,  8063,  8145,  8222,  8230,  8278,  8311,  8339,  8354,\n",
            "          8368,  8373,  8474,  8482,  8527,  8557,  8558,  8582,  8589,  8770,\n",
            "          8906,  8921,  9084,  9121,  9366,  9402,  9595,  9610,  9621,  9629,\n",
            "          9687,  9810,  9849,  9976, 10219, 10290, 10376, 10453, 10475, 10486,\n",
            "         10491, 10536, 10620, 10624, 10665, 10724, 10817, 10874, 10958, 11099,\n",
            "         11164, 11185, 11442, 11494, 11519, 11550, 11657, 11746, 11749, 11844,\n",
            "         11969, 11981, 12042, 12047, 12121, 12122, 12188, 12197, 12215, 12335,\n",
            "         12348, 12349, 12362, 12394, 12421, 12422, 12423, 12429, 12458, 12492,\n",
            "         12503, 12528, 12554, 12555, 12567, 12618, 12846, 12886, 13049, 13096,\n",
            "         13198, 13203, 13335, 13339, 13351, 13519, 13565, 13797, 13822, 13838,\n",
            "         13878, 13935, 14007, 14047, 14059, 14273, 14304, 14326, 14332, 14343,\n",
            "         14350, 14365, 14372, 14376, 14468, 14626, 14654, 14659, 14851, 14872,\n",
            "         15118, 15183, 15213, 15413, 15445, 15489, 15682, 15688, 15779, 15790,\n",
            "         15818, 16020, 16023, 16026, 16120, 16144, 16176, 16334, 16355, 16541,\n",
            "         16545, 16559, 16819, 16922, 17019, 17076, 17107, 17202, 17226, 17245,\n",
            "         17304, 17338, 17418, 17421, 17440, 17624, 17879, 17883, 17887, 17891,\n",
            "         17946, 17961, 17975, 17990, 17998, 17999, 18008, 18010, 18011, 18049,\n",
            "         18112, 18127, 18251, 18258, 18274, 18417, 18549, 18584, 18586, 18643,\n",
            "         18816, 18899, 18919, 19112, 19216, 19352, 19395, 19396, 19418, 19507,\n",
            "         19538, 19556, 19639, 19711, 19745, 19748, 19791, 19792, 19802, 19902,\n",
            "         19912, 19926, 19932, 19934]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the MLP model\n",
        "\n",
        "* Now that all of our data is in shape, we can build the model\n",
        "* That is luckily quite easy in this case\n",
        "\n",
        "The model class in its simplest form has `__init__()` which instantiates the layers and `forward()` which implements the actual computation. For more information on these, please see the [PyTorch turorial](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html)."
      ],
      "metadata": {
        "id": "AOYYF5I1OWG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "# A model wants a config, I can simply inherit from the base\n",
        "# class for pretrained configs\n",
        "class MLPConfig(transformers.PretrainedConfig):\n",
        "    pass\n",
        "\n",
        "# This is the model\n",
        "class MLP(transformers.PreTrainedModel):\n",
        "\n",
        "    config_class=MLPConfig\n",
        "\n",
        "    # In the initialization method, one instantiates the layers\n",
        "    # these will be, for the most part the trained parameters of the model\n",
        "    def __init__(self,config):\n",
        "        super().__init__(config)\n",
        "        self.vocab_size=config.vocab_size #embedding matrix row count\n",
        "        # Build and initialize embedding of vocab size +1 x hidden size (+1 because of the padding index 0!)\n",
        "        self.embedding=torch.nn.Embedding(num_embeddings=self.vocab_size+1,embedding_dim=config.hidden_size,padding_idx=0)\n",
        "        # Normally you would not initialize these yourself, but I have my reasons here ;)\n",
        "        torch.nn.init.uniform_(self.embedding.weight.data,-0.001,0.001) #initialize the embeddings with small random values\n",
        "        # Note! This function is relatively clever and keeps the embedding for 0, the padding, pure zeros\n",
        "        # This takes care of the lower half of the network, now the upper half\n",
        "        # Output layer: hidden size x output size\n",
        "        self.output=torch.nn.Linear(in_features=config.hidden_size,out_features=config.nlabels)\n",
        "        # Now we have the parameters of the model\n",
        "\n",
        "\n",
        "    # The computation of the model is put into the forward() function\n",
        "    # it receives a batch of data and optionally the correct `labels`\n",
        "    #\n",
        "    # If given `labels` it returns (loss,output)\n",
        "    # if not, then it returns (output,)\n",
        "    def forward(self,input_ids,labels=None):\n",
        "        #1) sum up the embeddings of the items\n",
        "        embedded=self.embedding(input_ids) #(batch,ids)->(batch,ids,embedding_dim)\n",
        "        # Since the Embedding keeps the first row of the matrix pure zeros, we don't need to worry about the padding\n",
        "        # so next we sum the embeddings across the word dimension\n",
        "        # (batch,ids,embedding_dim) -> (batch,embedding_dim)\n",
        "        embedded_summed=torch.sum(embedded,dim=1)\n",
        "\n",
        "        #2) apply non-linearity\n",
        "        # (batch,embedding_dim) -> (batch,embedding_dim)\n",
        "        projected=torch.tanh(embedded_summed) #Note how non-linearity is applied here and not when configuring the layer in __init__()\n",
        "\n",
        "        #3) and now apply the upper, output layer of the network\n",
        "        # (batch,embedding_dim) -> (batch, num_of_classes i.e. 2 in our case)\n",
        "        logits=self.output(projected)\n",
        "\n",
        "        # ...and that's all there is to it!\n",
        "\n",
        "        #print(\"input_ids.shape\",input_ids.shape)\n",
        "        #print(\"embedded.shape\",embedded.shape)\n",
        "        #print(\"embedded_summed.shape\",embedded_summed.shape)\n",
        "        #print(\"projected.shape\",projected.shape)\n",
        "        #print(\"logits.shape\",logits.shape)\n",
        "\n",
        "        # If we have labels, we ought to calculate the loss\n",
        "        if labels is not None:\n",
        "            loss=torch.nn.CrossEntropyLoss() #This loss is meant for classification, so let's use it\n",
        "            # You run it as loss(model_output,correct_labels)\n",
        "            return (loss(logits,labels),logits)\n",
        "        else:\n",
        "            # No labels, so just return the logits\n",
        "            return (logits,)\n",
        "\n"
      ],
      "metadata": {
        "id": "vP4FtrMwCpGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the model:\n",
        "#   these parameters are used in the model's __init__()\n",
        "mlp_config=MLPConfig(vocab_size=len(vectorizer.vocabulary_),hidden_size=20,nlabels=2)\n",
        "\n",
        "# And now we can instantiate it\n",
        "mlp=MLP(mlp_config)\n",
        "\n",
        "#we can make a little test with a fake batch formed by the two first example\n",
        "fake_batch=collator([dset_tokenized[\"train\"][0],dset_tokenized[\"train\"][1]])\n",
        "mlp(**fake_batch) #** expands input_ids and labels as parameters of the call"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQjSGUYGwrzh",
        "outputId": "9383cc7c-3e0d-4d48-88bc-b7399b8ed149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.6656, grad_fn=<NllLossBackward0>),\n",
              " tensor([[-0.1499, -0.2098],\n",
              "         [-0.1472, -0.1990]], grad_fn=<AddmmBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "\n",
        "We will use the Hugging Face [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) class for training\n",
        "\n",
        "* Loads of arguments that control the training\n",
        "* Configurable metrics to evaluate performance\n",
        "* Data collator builds the batches\n",
        "* Early stopping callback stops when eval loss no longer improves\n",
        "* Model load/save\n",
        "* Excellent foundation for later deep learning course\n",
        "  "
      ],
      "metadata": {
        "id": "tdlcMObzQGGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's create a [`TrainingArguments`](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/trainer#transformers.TrainingArguments) object to specify hyperparameters and various other settings for training.\n",
        "\n",
        "Printing this simple dataclass object will show not only the values we set, but also the defaults for all other arguments. Don't worry if you don't understand what all of these do! Many are not relevant to us here, and you can find the details in [`Trainer` documentation](https://huggingface.co/docs/transformers/main_classes/trainer) if you are interested."
      ],
      "metadata": {
        "id": "aZgcNi4B76SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training arguments\n",
        "# their names are mostly self-explanatory\n",
        "\n",
        "#add two loops to go over various learning rates and batch sizes\n",
        "####################################################\n",
        "def training_arguments(learning_rate=1e-5, batch_size=128):\n",
        "  #######################################################################################\n",
        "  trainer_args = transformers.TrainingArguments(\n",
        "      \"mlp_checkpoints\", #save checkpoints here\n",
        "      evaluation_strategy=\"steps\",\n",
        "      logging_strategy=\"steps\",\n",
        "      eval_steps=500,\n",
        "      logging_steps=500,\n",
        "\n",
        "      ###########################################################################################\n",
        "      #Explore various learning rates\n",
        "      learning_rate=learning_rate, #1e-5, #learning rate of the gradient descent\n",
        "      ##########################################################################################\n",
        "\n",
        "      max_steps=20000,\n",
        "      load_best_model_at_end=True,\n",
        "      ####################################################################################\n",
        "      #Explore various batch sizes\n",
        "      per_device_train_batch_size=batch_size#128\n",
        "      #################################################################################\n",
        "  )\n",
        "\n",
        "  pprint(trainer_args)\n",
        "  return trainer_args"
      ],
      "metadata": {
        "id": "IhfdW62z8cCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's create a metric for evaluating performance during and after training. We can use the convenience function [`load_metric`](https://huggingface.co/docs/datasets/about_metrics) to load one of many pre-made metrics and wrap this for use by the trainer.\n",
        "\n",
        "As the task is simple binary classification and our data is even 50:50 balanced, we can comfortably use the basic `accuracy` metric, defined as the proportion of correctly predicted labels out of all labels."
      ],
      "metadata": {
        "id": "4sJwNXPU-dQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_accuracy(outputs_and_labels):\n",
        "    outputs, labels = outputs_and_labels\n",
        "    predictions = np.argmax(outputs, axis=-1) #pick the index of the \"winning\" label\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "u3jxIItb0BL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then create the `Trainer` and train the model by invoking the [`Trainer.train`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.train) function.\n",
        "\n",
        "In addition to the model, the settings passed in through the `TrainingArguments` object created above (`trainer_args`), the data, and the metric defined above, we create and pass the following to the `Trainer`:\n",
        "\n",
        "* [data collator](https://huggingface.co/docs/transformers/main_classes/data_collator): groups input into batches\n",
        "* [`EarlyStoppingCallback`](https://huggingface.co/docs/transformers/main_classes/callback#transformers.EarlyStoppingCallback): stops training when performance stops improving"
      ],
      "metadata": {
        "id": "S7kbz8uU-zpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a new model\n",
        "mlp = MLP(mlp_config)\n",
        "\n",
        "\n",
        "# Argument gives the number of steps of patience before early stopping\n",
        "# i.e. training is stopped when the evaluation loss fails to improve\n",
        "# certain number of times\n",
        "early_stopping = transformers.EarlyStoppingCallback(5)\n",
        "\n",
        "def trainers(trainer_args):\n",
        "  trainer = transformers.Trainer(\n",
        "      model=mlp,\n",
        "      args=trainer_args,\n",
        "      train_dataset=dset_tokenized[\"train\"],\n",
        "      eval_dataset=dset_tokenized[\"test\"].select(range(1000)), #make a smaller subset to evaluate on\n",
        "      compute_metrics=compute_accuracy,\n",
        "      data_collator=collator,\n",
        "      callbacks=[early_stopping]\n",
        "  )\n",
        "\n",
        "  # FINALLY!\n",
        "  trainer.train()\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "AoEoWsj4P_zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then evaluate the trained model on a given dataset (here our test subset) by calling [`Trainer.evaluate`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.evaluate):"
      ],
      "metadata": {
        "id": "Td03fcIa-6Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluations(trainer):\n",
        "    eval_results = trainer.evaluate(dset_tokenized[\"test\"])\n",
        "\n",
        "    print(eval_results)\n",
        "    return eval_results"
      ],
      "metadata": {
        "id": "9nlEwpnF2Vow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the model for later use\n",
        "\n",
        "* You can save it with `trainer.save_model()`\n",
        "* You can load it with `MLP.from_pretrained()`\n"
      ],
      "metadata": {
        "id": "P0OYB3TRp-IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(name=\"mlp-imdb\"):\n",
        "  trainer.save_model(name)"
      ],
      "metadata": {
        "id": "FosHTDw3p9dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check save/load"
      ],
      "metadata": {
        "id": "8D8W9EN-zMAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mlp2=MLP.from_pretrained(\"mlp-imdb\")"
      ],
      "metadata": {
        "id": "UKMMNbABqLTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "trainer = transformers.Trainer(\n",
        "    model=mlp2,\n",
        "    args=trainer_args,\n",
        "    train_dataset=dset_tokenized[\"train\"],\n",
        "    eval_dataset=dset_tokenized[\"test\"],\n",
        "    compute_metrics=compute_accuracy,\n",
        "    data_collator=collator,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "id": "pfLnUENrrCyp",
        "outputId": "fd4bcf3c-f9c3-4aa8-bc31-ba5be7c81e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrainer = transformers.Trainer(\\n    model=mlp2,\\n    args=trainer_args,\\n    train_dataset=dset_tokenized[\"train\"],\\n    eval_dataset=dset_tokenized[\"test\"],\\n    compute_metrics=compute_accuracy,\\n    data_collator=collator,\\n    callbacks=[early_stopping]\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "eval_results = trainer.evaluate(dset_tokenized[\"test\"])\n",
        "print(eval_results)\n",
        "print('Accuracy:', eval_results['eval_accuracy'])\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hpOM2ZwErMGf",
        "outputId": "36ed8aad-09d6-4070-dcd5-8030bae2dd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\neval_results = trainer.evaluate(dset_tokenized[\"test\"])\\nprint(eval_results)\\nprint(\\'Accuracy:\\', eval_results[\\'eval_accuracy\\'])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra time left?\n",
        "\n",
        "* Read through the TrainingArguments documentation, try to understand at least some parts of it https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\n",
        "* Read through Torch tensor operations, try to understand at least some parts of it: https://pytorch.org/docs/stable/tensors.html\n",
        "* Run the model with different parameters (hidden layer width, learning rate, etc), how much do the results change?\n"
      ],
      "metadata": {
        "id": "8UT5MV1LtSBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What has the model learned?\n",
        "\n",
        "* The embeddings should have some meaning to them\n",
        "* Similar features should have similar embeddings"
      ],
      "metadata": {
        "id": "13aB7DuqzeFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab the embedding matrix out of the trained model\n",
        "# and drop the first row (padding 0)\n",
        "# then we can treat the embeddings as vectors\n",
        "# and maybe compare them to each other\n",
        "# ha ha this below took some googling\n",
        "weights=mlp.embedding.weight.detach().cpu().numpy()\n",
        "weights=weights[1:,:]"
      ],
      "metadata": {
        "id": "M6TUrVkMCmz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qry_idx=vectorizer.vocabulary_[\"great\"] #embedding of \"great\"\n",
        "\n",
        "#calculate the distance of the \"lousy\" embedding to all other embeddings\n",
        "distance_to_qry=sklearn.metrics.pairwise.euclidean_distances(weights[qry_idx:qry_idx+1,:],weights)\n",
        "nearest_neighbors=np.argsort(distance_to_qry) #indices of words nearest to \"lousy\"\n",
        "for nearest in nearest_neighbors[0,:20]:\n",
        "    print(idx2word[nearest])\n",
        "# This works great!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uTTvRgGDU9D",
        "outputId": "322e3ace-01e3-433c-d2c1-60f77b6fb9d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "great\n",
            "sponge\n",
            "illusion\n",
            "guns\n",
            "onslaught\n",
            "aggressively\n",
            "desk\n",
            "computer\n",
            "limited\n",
            "judy\n",
            "anachronisms\n",
            "prison\n",
            "se7en\n",
            "csi\n",
            "ana\n",
            "mini\n",
            "spot\n",
            "winded\n",
            "maids\n",
            "seagal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The embeddings indeed seem to reflect the task\n",
        "* There is a meaning to them"
      ],
      "metadata": {
        "id": "cQCmThdu2LDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature weights\n",
        "\n",
        "*   A typical \"old-school\" way to approach the classification would be a simple linear model, like LinearSVM\n",
        "*   Under such model, each feature (word) would have a single one weight\n",
        "*   And the classification would simply be based on the sum of these weights\n",
        "*   In this context of this task, \"positive\" words would get a high weight, \"negative\" words would get a low weight\n",
        "*   It is in fact quite easy to reconfigure the MLP model to work more or less like this and this effect can be replicated\n",
        "*   I will leave that as an exercise for you\n",
        "\n"
      ],
      "metadata": {
        "id": "Jydy3ECK3O2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
        "batch_sizes = [10, 20, 40, 64, 128]\n",
        "results = []\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        trainer_arg = training_arguments(learning_rate, batch_size)\n",
        "        print('trainer_arg:\\n', trainer_arg)\n",
        "\n",
        "        trainer = trainers(trainer_arg)\n",
        "        print('trainer:\\n\\n', trainer)\n",
        "\n",
        "        print('evaluations:\\n\\n')\n",
        "        eval_results = evaluations(trainer)\n",
        "\n",
        "        save_model(f'lr={learning_rate}_bs={batch_size}')\n",
        "\n",
        "        result_entry = {\n",
        "            \"Learning Rate\": learning_rate,\n",
        "            \"Batch Size\": batch_size,\n",
        "            \"Epoch\": eval_results[\"epoch\"],\n",
        "            \"Validation Loss\": eval_results[\"eval_loss\"],\n",
        "            \"Accuracy\": eval_results[\"eval_accuracy\"],\n",
        "            \"Evaluation Runtime\": eval_results[\"eval_runtime\"]\n",
        "        }\n",
        "\n",
        "        results.append(result_entry)"
      ],
      "metadata": {
        "id": "f6EqsvkbcXWK",
        "outputId": "b43d8691-6119-4843-f622-19aecb19418f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-41-42_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-41-42_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4500' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 4500/20000 00:23 < 01:20, 193.10 it/s, Epoch 1/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.241477</td>\n",
              "      <td>0.912000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.167600</td>\n",
              "      <td>0.241842</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.159000</td>\n",
              "      <td>0.241809</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.165800</td>\n",
              "      <td>0.240573</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.163000</td>\n",
              "      <td>0.241113</td>\n",
              "      <td>0.911000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.155300</td>\n",
              "      <td>0.240691</td>\n",
              "      <td>0.911000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.154500</td>\n",
              "      <td>0.240888</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.156800</td>\n",
              "      <td>0.241254</td>\n",
              "      <td>0.912000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.171400</td>\n",
              "      <td>0.241017</td>\n",
              "      <td>0.912000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe314da50>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.2759925127029419, 'eval_accuracy': 0.89036, 'eval_runtime': 6.3747, 'eval_samples_per_second': 3921.737, 'eval_steps_per_second': 490.217, 'epoch': 1.8}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-42-13_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-42-13_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3500' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3500/20000 00:20 < 01:36, 170.28 it/s, Epoch 2/16]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.163100</td>\n",
              "      <td>0.241761</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.156600</td>\n",
              "      <td>0.240537</td>\n",
              "      <td>0.911000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.157700</td>\n",
              "      <td>0.240591</td>\n",
              "      <td>0.911000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.152400</td>\n",
              "      <td>0.241471</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.241472</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.151000</td>\n",
              "      <td>0.241382</td>\n",
              "      <td>0.911000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.153400</td>\n",
              "      <td>0.241290</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe1f60220>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.2764369249343872, 'eval_accuracy': 0.88976, 'eval_runtime': 7.0973, 'eval_samples_per_second': 3522.473, 'eval_steps_per_second': 440.309, 'epoch': 2.8}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-42-40_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-42-40_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:28 < 02:39, 106.29 it/s, Epoch 4/32]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.155400</td>\n",
              "      <td>0.241058</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.153400</td>\n",
              "      <td>0.242045</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.154200</td>\n",
              "      <td>0.241433</td>\n",
              "      <td>0.911000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.148200</td>\n",
              "      <td>0.241245</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.148300</td>\n",
              "      <td>0.242082</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.143500</td>\n",
              "      <td>0.241803</td>\n",
              "      <td>0.908000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe311f3d0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.27701419591903687, 'eval_accuracy': 0.88944, 'eval_runtime': 7.1388, 'eval_samples_per_second': 3502.003, 'eval_steps_per_second': 437.75, 'epoch': 4.8}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-43-16_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-43-16_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:32 < 03:02, 93.38 it/s, Epoch 7/52]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.152900</td>\n",
              "      <td>0.241658</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.152100</td>\n",
              "      <td>0.242248</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.144500</td>\n",
              "      <td>0.242446</td>\n",
              "      <td>0.911000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.143900</td>\n",
              "      <td>0.242621</td>\n",
              "      <td>0.909000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.143400</td>\n",
              "      <td>0.242542</td>\n",
              "      <td>0.908000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.137100</td>\n",
              "      <td>0.243236</td>\n",
              "      <td>0.907000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fc5f2d0400>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.2777872085571289, 'eval_accuracy': 0.88908, 'eval_runtime': 7.1506, 'eval_samples_per_second': 3496.22, 'eval_steps_per_second': 437.027, 'epoch': 7.67}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-43-56_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-43-56_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:53 < 05:05, 55.60 it/s, Epoch 15/103]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.149900</td>\n",
              "      <td>0.242375</td>\n",
              "      <td>0.911000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.143400</td>\n",
              "      <td>0.242402</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.141200</td>\n",
              "      <td>0.243158</td>\n",
              "      <td>0.908000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.136800</td>\n",
              "      <td>0.243450</td>\n",
              "      <td>0.907000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.132100</td>\n",
              "      <td>0.245199</td>\n",
              "      <td>0.907000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.128800</td>\n",
              "      <td>0.246148</td>\n",
              "      <td>0.908000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe314f700>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.278526246547699, 'eval_accuracy': 0.8888, 'eval_runtime': 7.1515, 'eval_samples_per_second': 3495.752, 'eval_steps_per_second': 436.969, 'epoch': 15.31}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-44-57_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-44-57_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:13 < 01:17, 220.56 it/s, Epoch 1/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.151600</td>\n",
              "      <td>0.251867</td>\n",
              "      <td>0.904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.153800</td>\n",
              "      <td>0.258995</td>\n",
              "      <td>0.904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.147300</td>\n",
              "      <td>0.256448</td>\n",
              "      <td>0.906000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.158300</td>\n",
              "      <td>0.260094</td>\n",
              "      <td>0.906000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.174100</td>\n",
              "      <td>0.265258</td>\n",
              "      <td>0.908000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.113500</td>\n",
              "      <td>0.274864</td>\n",
              "      <td>0.905000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fc4dd87730>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.2890869975090027, 'eval_accuracy': 0.88636, 'eval_runtime': 7.1556, 'eval_samples_per_second': 3493.743, 'eval_steps_per_second': 436.718, 'epoch': 1.2}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-45-18_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-45-18_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3500' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3500/20000 00:19 < 01:33, 176.74 it/s, Epoch 2/16]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.133700</td>\n",
              "      <td>0.270249</td>\n",
              "      <td>0.897000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.152500</td>\n",
              "      <td>0.259182</td>\n",
              "      <td>0.904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.141400</td>\n",
              "      <td>0.268813</td>\n",
              "      <td>0.905000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.111200</td>\n",
              "      <td>0.273461</td>\n",
              "      <td>0.901000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.126200</td>\n",
              "      <td>0.279917</td>\n",
              "      <td>0.902000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.294021</td>\n",
              "      <td>0.902000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.098800</td>\n",
              "      <td>0.302830</td>\n",
              "      <td>0.903000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe1f60100>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.30059102177619934, 'eval_accuracy': 0.88448, 'eval_runtime': 7.1773, 'eval_samples_per_second': 3483.195, 'eval_steps_per_second': 435.399, 'epoch': 2.8}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-45-46_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-45-46_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:24 < 02:19, 121.75 it/s, Epoch 4/32]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.111300</td>\n",
              "      <td>0.274691</td>\n",
              "      <td>0.895000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.118200</td>\n",
              "      <td>0.283789</td>\n",
              "      <td>0.902000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.095000</td>\n",
              "      <td>0.298467</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.081500</td>\n",
              "      <td>0.310130</td>\n",
              "      <td>0.897000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.072200</td>\n",
              "      <td>0.328025</td>\n",
              "      <td>0.895000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.058100</td>\n",
              "      <td>0.342011</td>\n",
              "      <td>0.891000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe3107340>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.3148577809333801, 'eval_accuracy': 0.88176, 'eval_runtime': 6.8484, 'eval_samples_per_second': 3650.465, 'eval_steps_per_second': 456.308, 'epoch': 4.8}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-46-18_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-46-18_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:32 < 03:03, 92.63 it/s, Epoch 7/52]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.106500</td>\n",
              "      <td>0.291314</td>\n",
              "      <td>0.894000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.087900</td>\n",
              "      <td>0.310445</td>\n",
              "      <td>0.891000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.069900</td>\n",
              "      <td>0.324553</td>\n",
              "      <td>0.891000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.058800</td>\n",
              "      <td>0.348622</td>\n",
              "      <td>0.886000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.049400</td>\n",
              "      <td>0.361229</td>\n",
              "      <td>0.887000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.039200</td>\n",
              "      <td>0.386267</td>\n",
              "      <td>0.879000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbec9e7700>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.33283862471580505, 'eval_accuracy': 0.87856, 'eval_runtime': 7.1985, 'eval_samples_per_second': 3472.96, 'eval_steps_per_second': 434.12, 'epoch': 7.67}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-46-58_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-46-58_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:54 < 05:10, 54.67 it/s, Epoch 15/103]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>0.316578</td>\n",
              "      <td>0.893000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.060500</td>\n",
              "      <td>0.338430</td>\n",
              "      <td>0.889000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.046500</td>\n",
              "      <td>0.362947</td>\n",
              "      <td>0.882000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.035700</td>\n",
              "      <td>0.395519</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.027200</td>\n",
              "      <td>0.428982</td>\n",
              "      <td>0.873000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.021300</td>\n",
              "      <td>0.456545</td>\n",
              "      <td>0.876000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fc4dd84850>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.36057618260383606, 'eval_accuracy': 0.87188, 'eval_runtime': 7.241, 'eval_samples_per_second': 3452.57, 'eval_steps_per_second': 431.571, 'epoch': 15.31}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-48-00_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-48-00_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 5000/20000 00:23 < 01:10, 214.11 it/s, Epoch 2/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.169700</td>\n",
              "      <td>0.624429</td>\n",
              "      <td>0.844000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.262300</td>\n",
              "      <td>0.427403</td>\n",
              "      <td>0.859000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.256900</td>\n",
              "      <td>0.364865</td>\n",
              "      <td>0.864000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.252500</td>\n",
              "      <td>0.324498</td>\n",
              "      <td>0.881000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.257000</td>\n",
              "      <td>0.304089</td>\n",
              "      <td>0.885000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.095800</td>\n",
              "      <td>0.429624</td>\n",
              "      <td>0.876000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.110700</td>\n",
              "      <td>0.444687</td>\n",
              "      <td>0.885000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.125800</td>\n",
              "      <td>0.429558</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.149200</td>\n",
              "      <td>0.413982</td>\n",
              "      <td>0.861000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>0.426431</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe464f310>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.3337298035621643, 'eval_accuracy': 0.86844, 'eval_runtime': 6.6183, 'eval_samples_per_second': 3777.413, 'eval_steps_per_second': 472.177, 'epoch': 2.0}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-48-30_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-48-30_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3500' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3500/20000 00:20 < 01:37, 170.06 it/s, Epoch 2/16]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.122900</td>\n",
              "      <td>0.439049</td>\n",
              "      <td>0.867000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.108200</td>\n",
              "      <td>0.410265</td>\n",
              "      <td>0.864000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.087100</td>\n",
              "      <td>0.533216</td>\n",
              "      <td>0.856000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.536038</td>\n",
              "      <td>0.864000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.076600</td>\n",
              "      <td>0.526941</td>\n",
              "      <td>0.865000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.025500</td>\n",
              "      <td>0.625565</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.032100</td>\n",
              "      <td>0.697114</td>\n",
              "      <td>0.847000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe31064a0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.4407638609409332, 'eval_accuracy': 0.8542, 'eval_runtime': 7.2851, 'eval_samples_per_second': 3431.661, 'eval_steps_per_second': 428.958, 'epoch': 2.8}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-48-59_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-48-59_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:24 < 02:20, 121.01 it/s, Epoch 4/32]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.052500</td>\n",
              "      <td>0.513052</td>\n",
              "      <td>0.851000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.066200</td>\n",
              "      <td>0.593031</td>\n",
              "      <td>0.854000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.032100</td>\n",
              "      <td>0.679814</td>\n",
              "      <td>0.848000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.016800</td>\n",
              "      <td>0.766635</td>\n",
              "      <td>0.848000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.008300</td>\n",
              "      <td>0.820481</td>\n",
              "      <td>0.847000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.908732</td>\n",
              "      <td>0.846000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fc4dd840d0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5606281757354736, 'eval_accuracy': 0.84744, 'eval_runtime': 6.572, 'eval_samples_per_second': 3804.024, 'eval_steps_per_second': 475.503, 'epoch': 4.8}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-49-30_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-49-30_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:33 < 03:09, 89.58 it/s, Epoch 7/52]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.054800</td>\n",
              "      <td>0.526959</td>\n",
              "      <td>0.855000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.765499</td>\n",
              "      <td>0.842000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.008400</td>\n",
              "      <td>0.838372</td>\n",
              "      <td>0.839000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.910974</td>\n",
              "      <td>0.834000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.957557</td>\n",
              "      <td>0.839000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>1.000707</td>\n",
              "      <td>0.841000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe1ddada0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5720695853233337, 'eval_accuracy': 0.85148, 'eval_runtime': 7.1507, 'eval_samples_per_second': 3496.149, 'eval_steps_per_second': 437.019, 'epoch': 7.67}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-50-11_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-50-11_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:55 < 05:16, 53.64 it/s, Epoch 15/103]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.019800</td>\n",
              "      <td>0.846230</td>\n",
              "      <td>0.842000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>0.959302</td>\n",
              "      <td>0.834000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>1.036703</td>\n",
              "      <td>0.841000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>1.104319</td>\n",
              "      <td>0.841000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.168866</td>\n",
              "      <td>0.842000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.218564</td>\n",
              "      <td>0.845000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbed914dc0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.9076173305511475, 'eval_accuracy': 0.83528, 'eval_runtime': 7.2007, 'eval_samples_per_second': 3471.903, 'eval_steps_per_second': 433.988, 'epoch': 15.31}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-51-15_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-51-15_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 5000/20000 00:23 < 01:10, 213.44 it/s, Epoch 2/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.243900</td>\n",
              "      <td>0.412087</td>\n",
              "      <td>0.823000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.255200</td>\n",
              "      <td>0.346729</td>\n",
              "      <td>0.868000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.250200</td>\n",
              "      <td>0.346610</td>\n",
              "      <td>0.854000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.244400</td>\n",
              "      <td>0.308654</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.249300</td>\n",
              "      <td>0.296213</td>\n",
              "      <td>0.876000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.118900</td>\n",
              "      <td>0.343669</td>\n",
              "      <td>0.871000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.128200</td>\n",
              "      <td>0.392380</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.143200</td>\n",
              "      <td>0.357885</td>\n",
              "      <td>0.862000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.158100</td>\n",
              "      <td>0.343944</td>\n",
              "      <td>0.871000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.166200</td>\n",
              "      <td>0.354328</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fd37b80910>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.3206346333026886, 'eval_accuracy': 0.8654, 'eval_runtime': 6.3909, 'eval_samples_per_second': 3911.837, 'eval_steps_per_second': 488.98, 'epoch': 2.0}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-51-45_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-51-45_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3500' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3500/20000 00:21 < 01:39, 166.25 it/s, Epoch 2/16]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.119300</td>\n",
              "      <td>0.368978</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.322946</td>\n",
              "      <td>0.885000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.115300</td>\n",
              "      <td>0.395178</td>\n",
              "      <td>0.865000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.079800</td>\n",
              "      <td>0.429721</td>\n",
              "      <td>0.862000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.106500</td>\n",
              "      <td>0.404550</td>\n",
              "      <td>0.866000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.048800</td>\n",
              "      <td>0.500578</td>\n",
              "      <td>0.857000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.057900</td>\n",
              "      <td>0.508168</td>\n",
              "      <td>0.868000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe314d090>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.36807364225387573, 'eval_accuracy': 0.85724, 'eval_runtime': 7.1581, 'eval_samples_per_second': 3492.557, 'eval_steps_per_second': 436.57, 'epoch': 2.8}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-52-14_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-52-14_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:24 < 02:19, 121.53 it/s, Epoch 4/32]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.066500</td>\n",
              "      <td>0.451010</td>\n",
              "      <td>0.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.089200</td>\n",
              "      <td>0.491331</td>\n",
              "      <td>0.867000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.576027</td>\n",
              "      <td>0.866000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.029400</td>\n",
              "      <td>0.594731</td>\n",
              "      <td>0.861000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.021200</td>\n",
              "      <td>0.563626</td>\n",
              "      <td>0.856000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.014800</td>\n",
              "      <td>0.628294</td>\n",
              "      <td>0.857000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fc4dd84850>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.4886847138404846, 'eval_accuracy': 0.85024, 'eval_runtime': 6.3469, 'eval_samples_per_second': 3938.957, 'eval_steps_per_second': 492.37, 'epoch': 4.8}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-52-45_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-52-45_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:33 < 03:07, 90.62 it/s, Epoch 7/52]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.067400</td>\n",
              "      <td>0.462918</td>\n",
              "      <td>0.866000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.044900</td>\n",
              "      <td>0.511211</td>\n",
              "      <td>0.867000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.021100</td>\n",
              "      <td>0.581352</td>\n",
              "      <td>0.857000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.015900</td>\n",
              "      <td>0.595902</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.012300</td>\n",
              "      <td>0.575449</td>\n",
              "      <td>0.866000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.008400</td>\n",
              "      <td>0.613040</td>\n",
              "      <td>0.867000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe1f612d0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5025244355201721, 'eval_accuracy': 0.85596, 'eval_runtime': 7.1523, 'eval_samples_per_second': 3495.388, 'eval_steps_per_second': 436.924, 'epoch': 7.67}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-53-26_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.01,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-53-26_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:54 < 05:10, 54.78 it/s, Epoch 15/103]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.033800</td>\n",
              "      <td>0.565572</td>\n",
              "      <td>0.871000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.012300</td>\n",
              "      <td>0.620952</td>\n",
              "      <td>0.871000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.008500</td>\n",
              "      <td>0.635676</td>\n",
              "      <td>0.865000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.006200</td>\n",
              "      <td>0.645501</td>\n",
              "      <td>0.864000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.004700</td>\n",
              "      <td>0.662583</td>\n",
              "      <td>0.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>0.698503</td>\n",
              "      <td>0.862000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe311e7d0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6252633929252625, 'eval_accuracy': 0.85308, 'eval_runtime': 7.1462, 'eval_samples_per_second': 3498.36, 'eval_steps_per_second': 437.295, 'epoch': 15.31}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-54-28_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-54-28_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=10,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3500' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3500/20000 00:16 < 01:16, 214.55 it/s, Epoch 1/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.385700</td>\n",
              "      <td>0.477549</td>\n",
              "      <td>0.847000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.410600</td>\n",
              "      <td>0.397177</td>\n",
              "      <td>0.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.411900</td>\n",
              "      <td>0.507657</td>\n",
              "      <td>0.816000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.420800</td>\n",
              "      <td>0.508574</td>\n",
              "      <td>0.831000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.411900</td>\n",
              "      <td>0.473576</td>\n",
              "      <td>0.804000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.333700</td>\n",
              "      <td>0.447484</td>\n",
              "      <td>0.841000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.342300</td>\n",
              "      <td>0.449217</td>\n",
              "      <td>0.840000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe1e10730>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.4193153977394104, 'eval_accuracy': 0.82948, 'eval_runtime': 7.1076, 'eval_samples_per_second': 3517.348, 'eval_steps_per_second': 439.669, 'epoch': 1.4}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-54-52_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-54-52_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=20,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 5000/20000 00:29 < 01:28, 169.90 it/s, Epoch 4/16]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.273500</td>\n",
              "      <td>0.377962</td>\n",
              "      <td>0.843000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.358300</td>\n",
              "      <td>0.408361</td>\n",
              "      <td>0.857000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.329700</td>\n",
              "      <td>0.398496</td>\n",
              "      <td>0.867000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.279700</td>\n",
              "      <td>0.452180</td>\n",
              "      <td>0.819000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.309800</td>\n",
              "      <td>0.344238</td>\n",
              "      <td>0.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.259600</td>\n",
              "      <td>0.358065</td>\n",
              "      <td>0.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.256700</td>\n",
              "      <td>0.377864</td>\n",
              "      <td>0.848000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.261800</td>\n",
              "      <td>0.372189</td>\n",
              "      <td>0.868000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.253900</td>\n",
              "      <td>0.370768</td>\n",
              "      <td>0.871000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.251700</td>\n",
              "      <td>0.352893</td>\n",
              "      <td>0.846000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe315a470>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.3860913813114166, 'eval_accuracy': 0.84008, 'eval_runtime': 7.1804, 'eval_samples_per_second': 3481.714, 'eval_steps_per_second': 435.214, 'epoch': 4.0}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-55-29_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-55-29_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=40,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 5000/20000 00:41 < 02:04, 120.85 it/s, Epoch 8/32]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.243300</td>\n",
              "      <td>0.348753</td>\n",
              "      <td>0.855000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.232700</td>\n",
              "      <td>0.472439</td>\n",
              "      <td>0.846000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.229400</td>\n",
              "      <td>0.422919</td>\n",
              "      <td>0.851000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.211400</td>\n",
              "      <td>0.401548</td>\n",
              "      <td>0.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.197000</td>\n",
              "      <td>0.324211</td>\n",
              "      <td>0.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.205500</td>\n",
              "      <td>0.383526</td>\n",
              "      <td>0.861000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.198800</td>\n",
              "      <td>0.398815</td>\n",
              "      <td>0.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.195600</td>\n",
              "      <td>0.418291</td>\n",
              "      <td>0.834000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.178300</td>\n",
              "      <td>0.387609</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.171800</td>\n",
              "      <td>0.352038</td>\n",
              "      <td>0.867000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe1f612d0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.35955163836479187, 'eval_accuracy': 0.86212, 'eval_runtime': 7.1825, 'eval_samples_per_second': 3480.678, 'eval_steps_per_second': 435.085, 'epoch': 8.0}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-56-18_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-56-18_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 5000/20000 00:55 < 02:45, 90.61 it/s, Epoch 12/52]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.191600</td>\n",
              "      <td>0.393757</td>\n",
              "      <td>0.856000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.184600</td>\n",
              "      <td>0.375594</td>\n",
              "      <td>0.853000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.175800</td>\n",
              "      <td>0.397019</td>\n",
              "      <td>0.866000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.155300</td>\n",
              "      <td>0.433610</td>\n",
              "      <td>0.862000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.163900</td>\n",
              "      <td>0.340038</td>\n",
              "      <td>0.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.144600</td>\n",
              "      <td>0.380073</td>\n",
              "      <td>0.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.143400</td>\n",
              "      <td>0.395229</td>\n",
              "      <td>0.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.140300</td>\n",
              "      <td>0.445143</td>\n",
              "      <td>0.873000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.126000</td>\n",
              "      <td>0.383828</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.122300</td>\n",
              "      <td>0.403312</td>\n",
              "      <td>0.877000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbed914dc0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.37877383828163147, 'eval_accuracy': 0.86424, 'eval_runtime': 7.1352, 'eval_samples_per_second': 3503.745, 'eval_steps_per_second': 437.968, 'epoch': 12.79}\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-57-20_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "trainer_arg:\n",
            " TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.1,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar31_22-57-20_0c516e1972ce,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3000/20000 00:55 < 05:16, 53.72 it/s, Epoch 15/103]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.132300</td>\n",
              "      <td>0.368512</td>\n",
              "      <td>0.868000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.115600</td>\n",
              "      <td>0.456897</td>\n",
              "      <td>0.869000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.105800</td>\n",
              "      <td>0.422278</td>\n",
              "      <td>0.879000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.097500</td>\n",
              "      <td>0.445252</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.087100</td>\n",
              "      <td>0.502155</td>\n",
              "      <td>0.867000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.078300</td>\n",
              "      <td>0.390253</td>\n",
              "      <td>0.879000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "\n",
            " <transformers.trainer.Trainer object at 0x78fbe1f612d0>\n",
            "evaluations:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.3950929343700409, 'eval_accuracy': 0.86356, 'eval_runtime': 6.9262, 'eval_samples_per_second': 3609.467, 'eval_steps_per_second': 451.183, 'epoch': 15.31}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set font size\n",
        "plt.rcParams.update({'font.size': 6})\n",
        "\n",
        "# Initialize lists to store data for plotting\n",
        "accuracies_by_lr_bs = [[] for _ in range(len(learning_rates))]\n",
        "\n",
        "# Populate the lists\n",
        "for entry in results:\n",
        "    lr_idx = learning_rates.index(entry[\"Learning Rate\"])\n",
        "    bs_idx = batch_sizes.index(entry[\"Batch Size\"])\n",
        "    accuracies_by_lr_bs[lr_idx].append((entry[\"Evaluation Runtime\"], entry[\"Accuracy\"], lr_idx, bs_idx))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(18, 12))  # Enlarge figure size\n",
        "\n",
        "# Plot accuracy for each learning rate and batch size\n",
        "for lr, bs, acc_list in zip(learning_rates, batch_sizes, accuracies_by_lr_bs):\n",
        "    for runtime, acc, lr_idx, bs_idx in acc_list:\n",
        "        plt.scatter(runtime, acc, label=f'LR={lr}, BS={bs}')\n",
        "        plt.annotate(f'LR={lr}, BS={bs}', (runtime, acc), textcoords=\"offset points\", xytext=(15,15), ha='center')\n",
        "\n",
        "plt.xlabel('Evaluation Runtime (seconds)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs. Evaluation Runtime')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-VE9sdkxyYYS",
        "outputId": "8a68e34d-31c7-4c82-b6b0-a5e0dcefbd3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save results dictionary to a file using pickle\n",
        "with open('results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "\n",
        "# Download the file to your local machine\n",
        "from google.colab import files\n",
        "files.download('results.pkl')"
      ],
      "metadata": {
        "id": "hzh_CBlgzQ4y",
        "outputId": "963c19ea-6e4c-4c65-e054-95481f98c90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a33b424e-c7cc-44b5-b918-ed7a04667d7b\", \"results.pkl\", 1666)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the results.pkl file\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "xZyjQEjjYvzE",
        "outputId": "6749bcd4-00a8-4701-a06b-7d78c099f378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-568906b6-7b9c-4638-9fd1-6b9a87aee075\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-568906b6-7b9c-4638-9fd1-6b9a87aee075\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results.pkl to results.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "file_path = 'results.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    results = pickle.load(f)"
      ],
      "metadata": {
        "id": "3LzZROT9ZgAx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "id": "s6BM4HVrZlos",
        "outputId": "56eaa3d2-bdca-4a90-b451-664f521611be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Learning Rate': 1e-05, 'Batch Size': 10, 'Epoch': 1.8, 'Validation Loss': 0.2759925127029419, 'Accuracy': 0.89036, 'Evaluation Runtime': 6.3747}, {'Learning Rate': 1e-05, 'Batch Size': 20, 'Epoch': 2.8, 'Validation Loss': 0.2764369249343872, 'Accuracy': 0.88976, 'Evaluation Runtime': 7.0973}, {'Learning Rate': 1e-05, 'Batch Size': 40, 'Epoch': 4.8, 'Validation Loss': 0.27701419591903687, 'Accuracy': 0.88944, 'Evaluation Runtime': 7.1388}, {'Learning Rate': 1e-05, 'Batch Size': 64, 'Epoch': 7.67, 'Validation Loss': 0.2777872085571289, 'Accuracy': 0.88908, 'Evaluation Runtime': 7.1506}, {'Learning Rate': 1e-05, 'Batch Size': 128, 'Epoch': 15.31, 'Validation Loss': 0.278526246547699, 'Accuracy': 0.8888, 'Evaluation Runtime': 7.1515}, {'Learning Rate': 0.0001, 'Batch Size': 10, 'Epoch': 1.2, 'Validation Loss': 0.2890869975090027, 'Accuracy': 0.88636, 'Evaluation Runtime': 7.1556}, {'Learning Rate': 0.0001, 'Batch Size': 20, 'Epoch': 2.8, 'Validation Loss': 0.30059102177619934, 'Accuracy': 0.88448, 'Evaluation Runtime': 7.1773}, {'Learning Rate': 0.0001, 'Batch Size': 40, 'Epoch': 4.8, 'Validation Loss': 0.3148577809333801, 'Accuracy': 0.88176, 'Evaluation Runtime': 6.8484}, {'Learning Rate': 0.0001, 'Batch Size': 64, 'Epoch': 7.67, 'Validation Loss': 0.33283862471580505, 'Accuracy': 0.87856, 'Evaluation Runtime': 7.1985}, {'Learning Rate': 0.0001, 'Batch Size': 128, 'Epoch': 15.31, 'Validation Loss': 0.36057618260383606, 'Accuracy': 0.87188, 'Evaluation Runtime': 7.241}, {'Learning Rate': 0.001, 'Batch Size': 10, 'Epoch': 2.0, 'Validation Loss': 0.3337298035621643, 'Accuracy': 0.86844, 'Evaluation Runtime': 6.6183}, {'Learning Rate': 0.001, 'Batch Size': 20, 'Epoch': 2.8, 'Validation Loss': 0.4407638609409332, 'Accuracy': 0.8542, 'Evaluation Runtime': 7.2851}, {'Learning Rate': 0.001, 'Batch Size': 40, 'Epoch': 4.8, 'Validation Loss': 0.5606281757354736, 'Accuracy': 0.84744, 'Evaluation Runtime': 6.572}, {'Learning Rate': 0.001, 'Batch Size': 64, 'Epoch': 7.67, 'Validation Loss': 0.5720695853233337, 'Accuracy': 0.85148, 'Evaluation Runtime': 7.1507}, {'Learning Rate': 0.001, 'Batch Size': 128, 'Epoch': 15.31, 'Validation Loss': 0.9076173305511475, 'Accuracy': 0.83528, 'Evaluation Runtime': 7.2007}, {'Learning Rate': 0.01, 'Batch Size': 10, 'Epoch': 2.0, 'Validation Loss': 0.3206346333026886, 'Accuracy': 0.8654, 'Evaluation Runtime': 6.3909}, {'Learning Rate': 0.01, 'Batch Size': 20, 'Epoch': 2.8, 'Validation Loss': 0.36807364225387573, 'Accuracy': 0.85724, 'Evaluation Runtime': 7.1581}, {'Learning Rate': 0.01, 'Batch Size': 40, 'Epoch': 4.8, 'Validation Loss': 0.4886847138404846, 'Accuracy': 0.85024, 'Evaluation Runtime': 6.3469}, {'Learning Rate': 0.01, 'Batch Size': 64, 'Epoch': 7.67, 'Validation Loss': 0.5025244355201721, 'Accuracy': 0.85596, 'Evaluation Runtime': 7.1523}, {'Learning Rate': 0.01, 'Batch Size': 128, 'Epoch': 15.31, 'Validation Loss': 0.6252633929252625, 'Accuracy': 0.85308, 'Evaluation Runtime': 7.1462}, {'Learning Rate': 0.1, 'Batch Size': 10, 'Epoch': 1.4, 'Validation Loss': 0.4193153977394104, 'Accuracy': 0.82948, 'Evaluation Runtime': 7.1076}, {'Learning Rate': 0.1, 'Batch Size': 20, 'Epoch': 4.0, 'Validation Loss': 0.3860913813114166, 'Accuracy': 0.84008, 'Evaluation Runtime': 7.1804}, {'Learning Rate': 0.1, 'Batch Size': 40, 'Epoch': 8.0, 'Validation Loss': 0.35955163836479187, 'Accuracy': 0.86212, 'Evaluation Runtime': 7.1825}, {'Learning Rate': 0.1, 'Batch Size': 64, 'Epoch': 12.79, 'Validation Loss': 0.37877383828163147, 'Accuracy': 0.86424, 'Evaluation Runtime': 7.1352}, {'Learning Rate': 0.1, 'Batch Size': 128, 'Epoch': 15.31, 'Validation Loss': 0.3950929343700409, 'Accuracy': 0.86356, 'Evaluation Runtime': 6.9262}]\n"
          ]
        }
      ]
    }
  ]
}