{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP+U8ohRZ/QVbpEC4im4j13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Introduction-to-Human-Language-Technology/blob/main/Excercise%20task%2010%3A%20word%20embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet sentence-splitter regex\n",
        "from sentence_splitter import SentenceSplitter\n",
        "import requests\n",
        "import regex\n",
        "!pip install gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "AbUO510K_A3u",
        "outputId": "649a24ac-8b9f-4d4f-8613-f652b4b4a895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the English dataset\n",
        "data_url = \"http://dl.turkunlp.org/TKO_7095_2023/enwiki-20220301-sample.txt\"\n",
        "response = requests.get(data_url)\n",
        "data = response.text"
      ],
      "metadata": {
        "id": "z3DdYWM2_ERO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split to paragraphs\n",
        "paragraphs = data.split('\\n')\n",
        "# As the udpipe tooks few hours, I select sentence splitter library.\n",
        "splitter = SentenceSplitter(language='en')"
      ],
      "metadata": {
        "id": "OqJbAIIe_H4_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "sentences = [s for p in paragraphs[:1000000] for s in splitter.split(p)]"
      ],
      "metadata": {
        "id": "CwtIBRrvAB-i",
        "outputId": "464f424c-f84b-46e4-c592-dd7a5b2cd96c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12min 18s, sys: 3.07 s, total: 12min 21s\n",
            "Wall time: 12min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "TOKENIZE_RE = regex.compile(r'([[:alnum:]]+|\\S)')"
      ],
      "metadata": {
        "id": "_NJWtn2-AOL8",
        "outputId": "0fdf7bd0-8bae-4247-b072-6c18939e74d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 664 µs, sys: 0 ns, total: 664 µs\n",
            "Wall time: 627 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tokenized_sentences = [TOKENIZE_RE.findall(s.lower()) for s in sentences]"
      ],
      "metadata": {
        "id": "RcFuwA60AYty",
        "outputId": "90af6f0c-7b7c-48d5-c326-e032fbf7954a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 10s, sys: 3.32 s, total: 1min 13s\n",
            "Wall time: 1min 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some first rows\n",
        "for i in range(10):\n",
        "    print(tokenized_sentences[i])"
      ],
      "metadata": {
        "id": "aYCdLpSy--4X",
        "outputId": "2abd31c6-4e13-4f7a-96b5-796740a0eaf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['incumbent', 'cm', 'mayawati', 'began', 'her', 'campaign', 'on', '27', 'january', 'at', 'a', 'rally', 'in', 'bijnor', '.']\n",
            "['on', '15', 'january', ',', 'she', 'released', 'the', 'bsp', \"'\", 's', 'list', 'of', 'candidates', 'for', 'all', 'the', '403', 'constituencies', '.']\n",
            "['the', 'list', 'included', '88', 'candidates', 'belonging', 'to', 'scs', ',', '113', 'from', 'obcs', ',', '85', 'religious', 'minorities', 'and', '117', 'upper', 'castes', ',', 'out', 'of', 'which', '74', 'are', 'brahmins', '.']\n",
            "['as', 'a', 'member', 'of', 'the', 'oss', 'research', 'and', 'analysis', 'division', ',', 'wheeler', 'had', 'government', 'security', 'clearance', 'to', 'received', 'secret', 'and', 'confidential', '\"', 'ditto', '\"', 'copies', 'of', 'monthly', 'and', 'semi', '-', 'monthly', 'reports', 'of', 'political', 'developments', 'throughout', 'the', 'world', '.']\n",
            "['wheeler', 'is', 'alleged', 'to', 'have', 'passed', 'these', 'reports', 'as', 'well', 'as', 'handwritten', 'and', 'typewritten', 'material', 'of', 'cable', 'reports', 'from', 'the', 'state', 'department', 'and', 'the', 'oss', 'to', 'soviet', 'intelligence', '.']\n",
            "['wheeler', 'is', 'alleged', 'to', 'have', 'provided', 'information', 'on', 'the', 'organization', 'and', 'policies', 'of', 'british', 'intelligence', 'services', 'and', 'furnished', 'memoranda', 'prepared', 'by', 'the', 'foreign', 'nationalities', 'branch', 'of', 'oss', 'on', 'material', 'relating', 'to', 'the', 'particular', 'racial', 'groups', 'and', 'activities', 'within', 'the', 'united', 'states', '.']\n",
            "['these', 'allegations', ',', 'launched', 'during', 'mccarthyism', 'resulted', 'in', 'no', 'charges', 'ever', 'being', 'brought', 'against', 'wheeler', ',', 'who', 'contended', 'that', 'the', 'charges', 'of', 'espionage', 'were', 'a', 'response', 'to', 'his', 'outspoken', 'criticism', 'of', 'the', 'failings', 'of', 'the', 'american', 'economic', 'and', 'political', 'system', '.']\n",
            "['lexicographic', 'preferences', 'have', 'also', 'been', 'found', 'useful', 'in', 'describing', 'choices', 'under', 'uncertainty', '.']\n",
            "['let', 'wi', '=', 'wi', '(', 'x', ',', 'p', '(', 'x', ')', ')', 'be', 'the', 'ith', 'utility', 'from', 'a', 'vector', 'of', 'prospects', 'x', '=', '(', 'x1', ',', 'â', '\\x80', '¦', ',', 'xk', ',', 'â', '\\x80', '¦', ')', 'which', 'has', 'associated', 'probabilities', 'p', '(', 'x', ')', '=', '(', 'p1', '(', 'x1', ')', ',', 'â', '\\x80', '¦', ',', 'pk', '(', 'xn', ')', ')', '.']\n",
            "['note', 'that', 'the', 'criterion', 'function', 'wi', 'depends', 'explicitly', 'not', 'only', 'on', 'x', 'but', 'also', 'on', 'the', 'probabilities', 'associated', 'with', 'x', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec\n",
        "model = Word2Vec(sentences=tokenized_sentences)"
      ],
      "metadata": {
        "id": "iat4CpX6AlUo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FInd similar Words to:\n",
        "words = [\"good\", \"bad\", \"dog\", \"cat\", \"king\", \"queen\"]\n",
        "similar_words = {}\n",
        "for word in words:\n",
        "    similar_words[word] = model.wv.most_similar(word)"
      ],
      "metadata": {
        "id": "ICNpcE-uA6xE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, similar in similar_words.items():\n",
        "    print(word, similar)"
      ],
      "metadata": {
        "id": "GCWAz66TECZP",
        "outputId": "0978b2ca-fe0c-4568-c21e-feeb748fb30f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good [('bad', 0.7764500379562378), ('decent', 0.7107490301132202), ('tough', 0.6820545196533203), ('perfect', 0.6808227896690369), ('genuine', 0.6517764329910278), ('sensible', 0.6490606665611267), ('happy', 0.6432491540908813), ('little', 0.6407383680343628), ('quiet', 0.6328219175338745), ('fun', 0.6302210688591003)]\n",
            "bad [('good', 0.7764500975608826), ('terrible', 0.6831875443458557), ('funny', 0.6592331528663635), ('horrible', 0.6534147262573242), ('tough', 0.6473285555839539), ('nasty', 0.6356762647628784), ('happy', 0.63502436876297), ('crazy', 0.6306237578392029), ('cute', 0.6289855241775513), ('poor', 0.6222598552703857)]\n",
            "dog [('cat', 0.8436651229858398), ('puppy', 0.7868298292160034), ('goat', 0.7807270288467407), ('rabbit', 0.7669864892959595), ('boar', 0.7664580345153809), ('dogs', 0.7599594593048096), ('pig', 0.7445487976074219), ('monkey', 0.7392084002494812), ('cow', 0.7383224368095398), ('pet', 0.7315573692321777)]\n",
            "cat [('rabbit', 0.8864553570747375), ('monkey', 0.8563873171806335), ('dog', 0.8436651825904846), ('snake', 0.7846265435218811), ('rat', 0.7812604904174805), ('toad', 0.7758762240409851), ('kitten', 0.7749996185302734), ('doll', 0.7713278532028198), ('crocodile', 0.7658456563949585), ('bunny', 0.763999879360199)]\n",
            "king [('prince', 0.8299431800842285), ('pretender', 0.7594119906425476), ('emperor', 0.7532248497009277), ('constantine', 0.7340734004974365), ('queen', 0.731600821018219), ('conqueror', 0.7243985533714294), ('tsar', 0.7155830264091492), ('regent', 0.71302330493927), ('confessor', 0.7108696103096008), ('aragon', 0.7080424427986145)]\n",
            "queen [('princess', 0.7889154553413391), ('king', 0.731600821018219), ('prince', 0.7042016983032227), ('coronation', 0.6774882078170776), ('empress', 0.6686111092567444), ('duchess', 0.6574873924255371), ('isabella', 0.646422803401947), ('lady', 0.6456505060195923), ('regent', 0.6446536183357239), ('consort', 0.6209909915924072)]\n"
          ]
        }
      ]
    }
  ]
}